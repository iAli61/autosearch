{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nougat/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing layout detection model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nougat/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DeformableDetrForObjectDetection were not initialized from the model checkpoint at Aryn/deformable-detr-DocLayNet and are newly initialized: ['bbox_embed.0.layers.1.weight', 'bbox_embed.0.layers.0.weight', 'class_embed.0.bias', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'bbox_embed.0.layers.2.bias', 'class_embed.0.weight', 'bbox_embed.0.layers.0.bias', 'bbox_embed.0.layers.1.bias', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'bbox_embed.0.layers.2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout detection service initialized. Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nougat/lib/python3.9/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/nougat/model.py:437: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  return torch.var(self.values, 1) / self.values.shape[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame rows: 647\n",
      "\n",
      "Starting bounding box normalization...\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing azure_document_intelligence element on page 1\n",
      "\n",
      "Processing layout_detector element on page 1\n",
      "\n",
      "Normalizing Layout box on page 1:\n",
      "Original coordinates (pixels): (189.48, 1604.11, 1597.6, 2097.01)\n",
      "After normalization (points): (63.16pt, 534.70pt, 532.53pt, 699.00pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing azure_document_intelligence element on page 2\n",
      "\n",
      "Processing layout_detector element on page 2\n",
      "\n",
      "Normalizing Layout box on page 2:\n",
      "Original coordinates (pixels): (189.92, 337.72, 1599.42, 1069.46)\n",
      "After normalization (points): (63.31pt, 112.57pt, 533.14pt, 356.49pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing azure_document_intelligence element on page 3\n",
      "\n",
      "Processing layout_detector element on page 3\n",
      "\n",
      "Normalizing Layout box on page 3:\n",
      "Original coordinates (pixels): (193.06, 331.78, 1594.8, 976.0)\n",
      "After normalization (points): (64.35pt, 110.59pt, 531.60pt, 325.33pt)\n",
      "\n",
      "Processing layout_detector element on page 3\n",
      "\n",
      "Normalizing Layout box on page 3:\n",
      "Original coordinates (pixels): (193.23, 1008.13, 1593.45, 1175.98)\n",
      "After normalization (points): (64.41pt, 336.04pt, 531.15pt, 391.99pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 4\n",
      "\n",
      "Processing azure_document_intelligence element on page 4\n",
      "\n",
      "Processing azure_document_intelligence element on page 4\n",
      "\n",
      "Processing azure_document_intelligence element on page 4\n",
      "\n",
      "Processing azure_document_intelligence element on page 4\n",
      "\n",
      "Processing azure_document_intelligence element on page 4\n",
      "\n",
      "Processing azure_document_intelligence element on page 4\n",
      "\n",
      "Processing azure_document_intelligence element on page 4\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing azure_document_intelligence element on page 5\n",
      "\n",
      "Processing layout_detector element on page 5\n",
      "\n",
      "Normalizing Layout box on page 5:\n",
      "Original coordinates (pixels): (191.45, 390.26, 1659.42, 800.96)\n",
      "After normalization (points): (63.82pt, 130.09pt, 553.14pt, 266.99pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing azure_document_intelligence element on page 6\n",
      "\n",
      "Processing layout_detector element on page 6\n",
      "\n",
      "Normalizing Layout box on page 6:\n",
      "Original coordinates (pixels): (208.24, 339.88, 1588.49, 846.05)\n",
      "After normalization (points): (69.41pt, 113.29pt, 529.50pt, 282.02pt)\n",
      "\n",
      "Processing layout_detector element on page 6\n",
      "\n",
      "Normalizing Layout box on page 6:\n",
      "Original coordinates (pixels): (208.34, 898.4, 1543.46, 1179.17)\n",
      "After normalization (points): (69.45pt, 299.47pt, 514.49pt, 393.06pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 7\n",
      "\n",
      "Processing azure_document_intelligence element on page 7\n",
      "\n",
      "Processing azure_document_intelligence element on page 7\n",
      "\n",
      "Processing azure_document_intelligence element on page 7\n",
      "\n",
      "Processing azure_document_intelligence element on page 7\n",
      "\n",
      "Processing azure_document_intelligence element on page 7\n",
      "\n",
      "Processing azure_document_intelligence element on page 7\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing azure_document_intelligence element on page 8\n",
      "\n",
      "Processing layout_detector element on page 8\n",
      "\n",
      "Normalizing Layout box on page 8:\n",
      "Original coordinates (pixels): (203.56, 399.86, 1592.03, 1141.19)\n",
      "After normalization (points): (67.85pt, 133.29pt, 530.68pt, 380.40pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing azure_document_intelligence element on page 9\n",
      "\n",
      "Processing layout_detector element on page 9\n",
      "\n",
      "Normalizing Layout box on page 9:\n",
      "Original coordinates (pixels): (193.57, 819.64, 1591.83, 1013.86)\n",
      "After normalization (points): (64.52pt, 273.21pt, 530.61pt, 337.95pt)\n",
      "\n",
      "Processing layout_detector element on page 9\n",
      "\n",
      "Normalizing Layout box on page 9:\n",
      "Original coordinates (pixels): (205.09, 338.71, 1579.98, 766.35)\n",
      "After normalization (points): (68.36pt, 112.90pt, 526.66pt, 255.45pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing azure_document_intelligence element on page 10\n",
      "\n",
      "Processing layout_detector element on page 10\n",
      "\n",
      "Normalizing Layout box on page 10:\n",
      "Original coordinates (pixels): (206.5, 362.63, 1577.54, 1959.57)\n",
      "After normalization (points): (68.83pt, 120.88pt, 525.85pt, 653.19pt)\n",
      "\n",
      "Processing layout_detector element on page 10\n",
      "\n",
      "Normalizing Layout box on page 10:\n",
      "Original coordinates (pixels): (193.0, 2000.36, 1593.44, 2228.83)\n",
      "After normalization (points): (64.33pt, 666.79pt, 531.15pt, 742.94pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 11\n",
      "\n",
      "Processing azure_document_intelligence element on page 11\n",
      "\n",
      "Processing azure_document_intelligence element on page 11\n",
      "\n",
      "Processing azure_document_intelligence element on page 11\n",
      "\n",
      "Processing azure_document_intelligence element on page 11\n",
      "\n",
      "Processing azure_document_intelligence element on page 11\n",
      "\n",
      "Processing azure_document_intelligence element on page 12\n",
      "\n",
      "Processing azure_document_intelligence element on page 12\n",
      "\n",
      "Processing azure_document_intelligence element on page 12\n",
      "\n",
      "Processing azure_document_intelligence element on page 12\n",
      "\n",
      "Processing azure_document_intelligence element on page 12\n",
      "\n",
      "Processing azure_document_intelligence element on page 12\n",
      "\n",
      "Processing azure_document_intelligence element on page 12\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing azure_document_intelligence element on page 13\n",
      "\n",
      "Processing layout_detector element on page 13\n",
      "\n",
      "Normalizing Layout box on page 13:\n",
      "Original coordinates (pixels): (193.71, 1151.92, 1592.25, 1262.03)\n",
      "After normalization (points): (64.57pt, 383.97pt, 530.75pt, 420.68pt)\n",
      "\n",
      "Processing layout_detector element on page 13\n",
      "\n",
      "Normalizing Layout box on page 13:\n",
      "Original coordinates (pixels): (200.81, 333.52, 1582.59, 1113.29)\n",
      "After normalization (points): (66.94pt, 111.17pt, 527.53pt, 371.10pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing azure_document_intelligence element on page 14\n",
      "\n",
      "Processing layout_detector element on page 14\n",
      "\n",
      "Normalizing Layout box on page 14:\n",
      "Original coordinates (pixels): (212.49, 680.77, 1582.44, 1787.09)\n",
      "After normalization (points): (70.83pt, 226.92pt, 527.48pt, 595.70pt)\n",
      "\n",
      "Processing layout_detector element on page 14\n",
      "\n",
      "Normalizing Layout box on page 14:\n",
      "Original coordinates (pixels): (193.03, 1827.01, 1593.77, 2021.53)\n",
      "After normalization (points): (64.34pt, 609.00pt, 531.26pt, 673.84pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 15\n",
      "\n",
      "Processing azure_document_intelligence element on page 15\n",
      "\n",
      "Processing azure_document_intelligence element on page 15\n",
      "\n",
      "Processing azure_document_intelligence element on page 15\n",
      "\n",
      "Processing azure_document_intelligence element on page 15\n",
      "\n",
      "Processing azure_document_intelligence element on page 15\n",
      "\n",
      "Processing azure_document_intelligence element on page 15\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing azure_document_intelligence element on page 16\n",
      "\n",
      "Processing layout_detector element on page 16\n",
      "\n",
      "Normalizing Layout box on page 16:\n",
      "Original coordinates (pixels): (194.49, 1279.01, 1593.38, 1504.41)\n",
      "After normalization (points): (64.83pt, 426.34pt, 531.13pt, 501.47pt)\n",
      "\n",
      "Processing layout_detector element on page 16\n",
      "\n",
      "Normalizing Layout box on page 16:\n",
      "Original coordinates (pixels): (197.06, 364.96, 1562.57, 1223.8)\n",
      "After normalization (points): (65.69pt, 121.65pt, 520.86pt, 407.93pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 17\n",
      "\n",
      "Processing azure_document_intelligence element on page 17\n",
      "\n",
      "Processing azure_document_intelligence element on page 17\n",
      "\n",
      "Processing azure_document_intelligence element on page 17\n",
      "\n",
      "Processing azure_document_intelligence element on page 17\n",
      "\n",
      "Processing azure_document_intelligence element on page 17\n",
      "\n",
      "Processing azure_document_intelligence element on page 18\n",
      "\n",
      "Processing azure_document_intelligence element on page 18\n",
      "\n",
      "Processing azure_document_intelligence element on page 18\n",
      "\n",
      "Processing azure_document_intelligence element on page 18\n",
      "\n",
      "Processing azure_document_intelligence element on page 18\n",
      "\n",
      "Processing azure_document_intelligence element on page 18\n",
      "\n",
      "Processing azure_document_intelligence element on page 18\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing azure_document_intelligence element on page 19\n",
      "\n",
      "Processing layout_detector element on page 19\n",
      "\n",
      "Normalizing Layout box on page 19:\n",
      "Original coordinates (pixels): (191.83, 389.87, 1635.41, 659.85)\n",
      "After normalization (points): (63.94pt, 129.96pt, 545.14pt, 219.95pt)\n",
      "\n",
      "Processing azure_document_intelligence element on page 20\n",
      "\n",
      "Processing azure_document_intelligence element on page 20\n",
      "\n",
      "Processing azure_document_intelligence element on page 20\n",
      "\n",
      "Processing azure_document_intelligence element on page 20\n",
      "\n",
      "Processing azure_document_intelligence element on page 20\n",
      "\n",
      "Processing azure_document_intelligence element on page 20\n",
      "\n",
      "Processing azure_document_intelligence element on page 20\n",
      "\n",
      "Processing azure_document_intelligence element on page 20\n",
      "\n",
      "Processing azure_document_intelligence element on page 21\n",
      "\n",
      "Processing azure_document_intelligence element on page 21\n",
      "\n",
      "Processing azure_document_intelligence element on page 21\n",
      "\n",
      "Processing azure_document_intelligence element on page 21\n",
      "\n",
      "Processing azure_document_intelligence element on page 21\n",
      "\n",
      "Processing azure_document_intelligence element on page 21\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 22\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 23\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 24\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 25\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 26\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 27\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "\n",
      "Processing azure_document_intelligence element on page 28\n",
      "Found significant overlap (0.72):\n",
      "Azure element: 1 Introduction...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Data generation, acquisition and management...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 2.1 Scientific literature...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 2.2 High-throughput and autonomous computational agents...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 2.3 Hypothetical polymers...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 3 Polymer representation...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 4 Property prediction schemes...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 4.1 Linear/Non-linear regression ....\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 4.2 Multi-fidelity information fusion approaches...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 4.3 Deep neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . ....\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.98):\n",
      "Azure element: . . . . . . . . . . . 12...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 4.4 Polymer Genome online platform...\n",
      "Layout element: Introduction\n",
      "* 2 Data generation, acquisition and management\n",
      "\t* 2.1 Scientific literature\n",
      "\t* 2.2 Hig...\n",
      "Found significant overlap (0.69):\n",
      "Azure element: 5 Polymer design algorithms...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 5.1 Enumeration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ....\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.95):\n",
      "Azure element: . . . . . . 13...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 5.2 Sequential (Active) learning...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 5.3 Evolutionary strategies ....\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 5.4 Generative models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ....\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.95):\n",
      "Azure element: . . . . . . 17...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Application examples...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 6.1 Polymer dielectrics design for high energy density capacitors ....\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 6.2 Polymer membrane design for gas separation...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 6.3 Polymer electrolytes design for Li-ion batteries...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 6.4 Conducting polymers design for electronic applications...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 6.5 Biodegradable and depolymerizable polymers discovery . . . . . . . . . . . . . . ....\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.95):\n",
      "Azure element: . . . . . . 20...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 7 Critical next steps...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 7.1 Beyond homopolymers...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 7.2 Sustainable data capture...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 7.3 Polymer representation and learning...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 7.4 Polymer retro-synthesis planning...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: 7.5 Autonomous integration of experimental and computational workflows...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 8 Acknowledgments...\n",
      "Layout element: * 5 Polymer design algorithms\n",
      "\t* 5.1 Enumeration\n",
      "\t* 5.2 Sequential (Active) learning\n",
      "\t* 5.3 Evolutio...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer Informatics Ecosystem...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 111000101 10110101010 (1000101017...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 1. Polymer Data...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Computational data...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Experimental data...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Data mining & curation High-throughput computation & experiments natural language processing...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 2. Polymer Representations...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Unique, complete, minimal descriptors (numeric information)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Hierarchical fingerprinting Chem Informatics Variational or graph autoencoders...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 3. Artificial Intelligence (AI) Prediction Regression Multi-fidelity information-fusion Deep neural ...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 4. User Interface...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: New polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Instant property prediction...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Design Enumeration Active learning Genetic or generative algorithms...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Targeted property...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Accelerated polymer design...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Feedforward new information for adaptive data augmentation...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 5. Synthesis / Computation AI-aided polymer synthesis planning AI-guided & automated data generation...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: AI-assisted expansion of polymer chemical / property space...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.98):\n",
      "Azure element: Figure 1: Essential elements of Polymer Informatics Ecosystem: 1) polymer data, derived from (high-t...\n",
      "Layout element: Figure 1: Essential elements of Polymer Informatics Ecosystem: 1) polymer data, derived from (high-t...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer Handbook [56], Handbook of Polymers [57], Properties of Polymers [58], Polymer Data Handbook...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Empirical Empirical Empirical...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: Online Repositories...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: PoLyInfo [28] CROW Polymer Property Database [60] Polymers: A property database [61]...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Empirical Empirical...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: CAMPUS [62] LANDOLT-BORNSTEIN [63] Polymer Property Predictor and Database (NIST) [64] Khazana [65]...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Computational...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: Published journal articles...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Empirical/Computational...\n",
      "Layout element: \\begin{tabular}{l l l} \\hline Source & Name & Data type \\\\ \\hline Handbook & Polymer Handbook [56], ...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: a) High-throughput computational models...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: b) Autonomous computational agents...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.65):\n",
      "Azure element: c) Hypothetical polymers generation...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Computational polymer data...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer candidates...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Machine learning model...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Select polymers for calculations...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 3D structure generator...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: High-throughput computations...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: · Job submission & management · Data quality control, etc....\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 9 most frequent fragments...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Known polymers (~13,000)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer fragments … (~3,000)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Hypothetical polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Hypothetical polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Hypothetical polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ~250,000 polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: (n = 2 to 7)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: Molecules:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Molecular fingerprint...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Binary vectors: presence (1) and absence (0) of substructures...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: ex) Nc1cccc(C(=O)O)c1...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Atomic-level descriptors ex) Atom-triples...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: + Block-level descriptors ex) Block-fragments...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: + Chain-level descriptors ex) Length of side-chain (ls)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.97):\n",
      "Azure element: Hierarchical polymer Fingerprint...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: C3-S2-C3 H1-N3-C4 S H C C...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: O N O HO N...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.96):\n",
      "Azure element: ex) [*]CC[*] (polyethylene)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: O\n",
      "C C O1-C3-C4 …...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: OH F F S N F …...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.98):\n",
      "Azure element: b) BigSMILES Representation...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Homo-polymers:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ex) {CC} ... Polyethylene...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Co-polymers:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ex) {CC, CC(C)} ... Poly(ethylene-co-propylene)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: a) Gaussian process regression (GPR)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: b) Multi-fidelity co-Kriging...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: c) Neural Network...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected: Observations True function...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: GPR predictions...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Uncertainty (o interval)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Low-fidelity yLF...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ZHF (X) = pZLF (X) + Za (X)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: High-fidelity yHF...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :unselected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :unselected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :unselected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :unselected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Hidden layer(s)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.98):\n",
      "Azure element: Output layer...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Figure 4: a) Gaussian process regression (GPR) model to learn the correlation between fingerprints a...\n",
      "Layout element: Figure 4: a) Gaussian process regression (GPR) model to learn the correlation between fingerprints a...\n",
      "Found significant overlap (0.47):\n",
      "Azure element: a) GPR prediction models...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.47):\n",
      "Azure element: b) Multi-fidelity prediction models...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Glass transition temperature...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 800 | 5076 data points RMSE100%=18.8 K RMSECV, test=35.3 K...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 10 Chain band gap 3881 data points RMSE100%=0.24 eV 8- RMSECV, test=0.5 eV...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :unselected: GPR train :selected: MF train...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: MF test ... 300 LF points . MF test ... 450 LF points...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: To MF train :unselected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ML predicted (K)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ML predicted (eV)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Experimental (K)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Dielectric constant...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 10 1193 data points...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: RMSE100%=0.16...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: RMSECV, test=0.19...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: DFT computed (eV)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Gas permeability 1779 data points...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: RMSE100%=1.2 Barrer...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: RMSECV, test=2.5 Barrer...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Band gap (eV)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Training datapoints...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: . GPR train GPR test . MF train...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: MF test ... 407 LF points MF test ... 429 LF points...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: . MF train...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ML predicted...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: . 60 Hz . 100 Hz...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ML predicted (log Barrer)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: RMSE (% tendency to crystallize)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 1 THz 1 PHz...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 6 Experimental...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Tendency to crystallize (%)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 15 25 35 45 55 65 75 85 Training set size (%)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Experimental (log Barrer)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: c) Neural network models for solvent prediction...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Neural network...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Hildebrand - GPR...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 0.881 0.704...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Accuracy (good-solvent)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 0.991 0.982...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 0.995 1.000...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Accuracy (non-solvent)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 0.821 0.706...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Diethyl ether...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Chloroform...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 1,4-dioxane...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Ethyl acetate...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Acetonitrile...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Acetic acid...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Chlorobenzene...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Nitrobenzene...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Isopropanol...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Dichloromethane...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Non-polar solvents...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polar-aprotic solvents...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polar-protic solvents...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.97):\n",
      "Azure element: Figure 5: a) Parity plots of GPR predicted and true values of the glass transition temperature, band...\n",
      "Layout element: Figure 5: a) Parity plots of GPR predicted and true values of the glass transition temperature, band...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: References Sign-in...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Electronic Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap (crystal)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap (chain)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Ionization energy...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Electron affinity...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Dielectric & Optical Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Static dielectric constant (crystal)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Frequency dependent dielectric constant...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Refractive index (bulk resin)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Refractive index (crystal)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Thermal Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Glass transition temperature...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Thermal decomposition temperature...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Melting temperature...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Specific heat...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Mechanical Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Tensile strength...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Young's modulus...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Physical Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Atomization energy...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 0.01 eV/atom...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Fractional free volume...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Solubility Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Hildebrand solubility parameter...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 0.47 Mpa1/2...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Solvent/non-solvent...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 93% accurate classification...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Permeability Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Gas permeability (H2, O2, N2,...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 1.2 Barrer...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: He, CO2, CH4)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Other Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Tendency to crystallize...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Limiting oxygen index...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: User input SMILES, name, abbreviation, sketch...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: General information Polymer class, IUPAC name, similar polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Predicted properties Polymer properties predicted by ML models...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Structure visualizer 3D structure of monomer, 'mol' file...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer Genome An informatics platform for polymer property prediction and design using machine leam...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Draw Polymer...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: polyfbicyclo(2.2.1]hept-2-ene, polynarbommene...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Predict Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: poly(bicycla[2.2.1]hept-2-ene], polynarbarnene...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Palyiniciopentane-1,3-diylethene-1,2-diy0)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: PPj-CE, CCOP.DCg Poydenel...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: COPY LIL REDBACK...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Electronic Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap (hulk] 5.82 05 eV...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap (Single Chain) 5.7 a 04 #V...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :unselected: Ionization Energi...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Electron Affinity...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Dielectric & Optical Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Thermal Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Frequency Dependent Dielectric Constant...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Gian Transition Temperature 136 & 38 K...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Melting Temperature...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Dielectric constard...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Mechanical Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Tensile Strength...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Young's Modulut 4 5646 MPa...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Firysical & Thermodynamic Properties Dielectric Constant (Crystal) 3.0 4 1.@...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Refractive index (Crystal 1.7 + 62...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Monicacion Energy 5.5 + 6.1 eWacom...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Specific Hast 2 a 1 pgK...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Solubilicy Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Nhexane Benzene Chlorobenzene Toluene Acetic acid Diethyl ether N-buranol Anesonitrile Chiesaform Di...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Non-solvent Methanol Acetone Ethanol isopropanol DIMSO Ethyl acetate muter 1,4-dionane...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Hildebrand Solubility Parameter...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Permitebeny Properties...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Atomic coordination...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer Genome atomic coordination...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 3.2490 0.1649 -1.9701 + 0 0 0...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 1.4223 -0.3319 -5.0014...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 9 -0.2527 0.1817...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: J -9.9706 C...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 1.6690 -0.5070 1.86PO N...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: Figure 6: a) Summary of various property prediction models implemented in the Polymer Genome online ...\n",
      "Layout element: Figure 6: a) Summary of various property prediction models implemented in the Polymer Genome online ...\n",
      "Found significant overlap (0.42):\n",
      "Azure element: a) Enumeration...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymers for extreme temperature & E-field...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymers for electronics & battery electrolytes...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap - Glass transition temperature - Dielectric constant...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Electron affinity - Bandgap - Ionization energy...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: ass transition temp. (K)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap, bulk (e)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap, bulk (ev)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Electron affinity (V)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Dielectric constant...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Dielectric constant...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Ionization energy (V)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymers for membranes Gas permeability - Gas selectivity 1 - Gas selectivity 2...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 02/CO2 selectivity...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 02 permeability (Barrer)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Ionization energy (eV)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 02/N2 selectivity...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap, bulk (ev)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Glass transition temp. (K)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Electron affinity (eV)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap, bulk (eV/)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Glass transition temperature...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Size : Electron affinity...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Size : Density...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.98):\n",
      "Azure element: b) Sequential (Active) learning...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Search strategies...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: new case recommendation...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: High-throughput computations...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: O2/N2 selectivity...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 02 permeability (Barrer)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 02/CO2 selectivity...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: H2 permeability...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 6e-6 barrer...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 1.8e6 barrer...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Size : He permeability...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: The use of active learning for polymer design...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Number of good polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Experimental validation...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Target candidates...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Exploitation...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Exploration...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: exploitation/exploration...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Number of virtual experiments...\n",
      "Layout element: No text...\n",
      "Found significant overlap (0.99):\n",
      "Azure element: Figure 7: a) ML predicted properties of ten-of-thousands of enumerated known/synthesizable polymers....\n",
      "Layout element: Figure 7: a) ML predicted properties of ten-of-thousands of enumerated known/synthesizable polymers....\n",
      "Found significant overlap (1.00):\n",
      "Azure element: P1-2 - Parent polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Genome breakdown position...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer Sequence Population...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: New polymers Known polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Targeted design area...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer Selection Objective function evaluation...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Crossover & Mutation New polymer offsprings using GA...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Bandgap, predicted (eV)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: G16-5 G7-8...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Property Prediction Supervised (GPR) surrogate models...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Glass transition temperature, predicted (K)...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Not mutated...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :unselected: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: :selected:...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: 01-4 - Offspring polymers...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Latent space...\n",
      "Layout element: No text...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Figure 8: Polymer inverse design using machine learning. Use of evolutionary algorithms, such as GA,...\n",
      "Layout element: Figure 8: Polymer inverse design using machine learning. Use of evolutionary algorithms, such as GA,...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Applications...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Representative desired polymer properties...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Capacitors (polymer dielectrics)...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Large band gap and high charge injection barriers high glass transition temperature and dielectric c...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Li-ion batteries (polymer electrolytes)...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Large electrochemical stability window, high ionic conductivity, high Li-ion transference and mechan...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Polymer membrane...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: High permeability and selectivity for gas pairs...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: Electronic devices (conducting polymers)...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Found significant overlap (1.00):\n",
      "Azure element: High electrical conductivity...\n",
      "Layout element: \\begin{tabular}{l l} \\hline Applications & Representative desired polymer properties \\\\ \\hline Capac...\n",
      "Rows after overlap filtering: 314\n",
      "Page 1 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_1_overlay.png\n",
      "Page 2 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_2_overlay.png\n",
      "Page 3 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_3_overlay.png\n",
      "Page 4 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_4_overlay.png\n",
      "Page 5 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_5_overlay.png\n",
      "Page 6 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_6_overlay.png\n",
      "Page 7 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_7_overlay.png\n",
      "Page 8 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_8_overlay.png\n",
      "Page 9 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_9_overlay.png\n",
      "Page 10 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_10_overlay.png\n",
      "Page 11 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_11_overlay.png\n",
      "Page 12 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_12_overlay.png\n",
      "Page 13 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_13_overlay.png\n",
      "Page 14 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_14_overlay.png\n",
      "Page 15 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_15_overlay.png\n",
      "Page 16 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_16_overlay.png\n",
      "Page 17 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_17_overlay.png\n",
      "Page 18 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_18_overlay.png\n",
      "Page 19 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_19_overlay.png\n",
      "Page 20 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_20_overlay.png\n",
      "Page 21 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_21_overlay.png\n",
      "Page 22 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_22_overlay.png\n",
      "Page 23 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_23_overlay.png\n",
      "Page 24 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_24_overlay.png\n",
      "Page 25 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_25_overlay.png\n",
      "Page 26 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_26_overlay.png\n",
      "Page 27 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_27_overlay.png\n",
      "Page 28 visualization: output-azure-0.55/1-s2.0-S0927796X2030053X-am.pdf-0.55/1-s2.0-S0927796X2030053X-am.pdf/visualizations/overlays/page_28_overlay.png\n",
      "Initializing layout detection model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nougat/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DeformableDetrForObjectDetection were not initialized from the model checkpoint at Aryn/deformable-detr-DocLayNet and are newly initialized: ['bbox_embed.0.layers.1.weight', 'bbox_embed.0.layers.0.weight', 'class_embed.0.bias', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'bbox_embed.0.layers.2.bias', 'class_embed.0.weight', 'bbox_embed.0.layers.0.bias', 'bbox_embed.0.layers.1.bias', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'bbox_embed.0.layers.2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout detection service initialized. Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Add these lines at the beginning of your notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from document_analysis import EnhancedDocumentAnalyzer\n",
    "from glob import glob\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the analyzer\n",
    "confidence_thresholds = [0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "pdfs_path = \"../tests/files\"\n",
    "pdf_paths = glob(f\"{pdfs_path}/*.pdf\")\n",
    "\n",
    "# Process a document\n",
    "for pdf_path in pdf_paths:\n",
    "    for ct in confidence_thresholds[0:1]:\n",
    "        output_dir = f\"output-azure/{ct}/{os.path.basename(pdf_path)}\"\n",
    "        analyzer = EnhancedDocumentAnalyzer(\n",
    "                api_key=os.getenv(\"DOCUMENT_INTELLIGENCE_KEY\"),\n",
    "                endpoint=os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\"),\n",
    "                output_dir=f\"{output_dir}-{ct}/{os.path.basename(pdf_path)}\",\n",
    "                confidence_threshold=0.5,\n",
    "                overlap_threshold=0.3  # More aggressive overlap detection\n",
    "            )\n",
    "\n",
    "        markdown_text, elements_df, visualization_paths  = analyzer.analyze_document(pdf_path)\n",
    "\n",
    "        # Save results\n",
    "        elements_df.to_csv(f\"{output_dir}/paper_elements.csv\", index=False)\n",
    "        with open(f\"{output_dir}/paper_analysis.md\", \"w\") as f:\n",
    "            f.write(markdown_text)\n",
    "\n",
    "        # The visualization_paths dict maps page numbers to visualization paths\n",
    "        for page_num, vis_path in visualization_paths.items():\n",
    "            print(f\"Page {page_num} visualization: {vis_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_file</th>\n",
       "      <th>page</th>\n",
       "      <th>bounding_box</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>image_path</th>\n",
       "      <th>role</th>\n",
       "      <th>confidence</th>\n",
       "      <th>spans</th>\n",
       "      <th>source</th>\n",
       "      <th>page_width</th>\n",
       "      <th>page_height</th>\n",
       "      <th>page_unit</th>\n",
       "      <th>normalized_box</th>\n",
       "      <th>y_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-s2.0-S0927796X2030053X-am.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.88, 0.21, 6.02, 0.54)</td>\n",
       "      <td>text</td>\n",
       "      <td>Version of Record: https://www.sciencedirect.c...</td>\n",
       "      <td>None</td>\n",
       "      <td>title</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'offset': 0, 'length': 130}]</td>\n",
       "      <td>azure_document_intelligence</td>\n",
       "      <td>8.2639</td>\n",
       "      <td>11.6806</td>\n",
       "      <td>inch</td>\n",
       "      <td>(63.36, 15.12, 433.44, 38.88)</td>\n",
       "      <td>15.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-s2.0-S0927796X2030053X-am.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>(1.49, 1.52, 6.75, 1.73)</td>\n",
       "      <td>text</td>\n",
       "      <td>Polymer Informatics: Current Status and Critic...</td>\n",
       "      <td>None</td>\n",
       "      <td>title</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'offset': 131, 'length': 59}]</td>\n",
       "      <td>azure_document_intelligence</td>\n",
       "      <td>8.2639</td>\n",
       "      <td>11.6806</td>\n",
       "      <td>inch</td>\n",
       "      <td>(107.28, 109.44, 486.00, 124.56)</td>\n",
       "      <td>109.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-s2.0-S0927796X2030053X-am.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>(1.24, 1.97, 7.02, 2.82)</td>\n",
       "      <td>text</td>\n",
       "      <td>Lihua Chenª, Ghanshyam Pilaniab, Rohit Batrac,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'offset': 191, 'length': 412}]</td>\n",
       "      <td>azure_document_intelligence</td>\n",
       "      <td>8.2639</td>\n",
       "      <td>11.6806</td>\n",
       "      <td>inch</td>\n",
       "      <td>(89.28, 141.84, 505.44, 203.04)</td>\n",
       "      <td>141.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-s2.0-S0927796X2030053X-am.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.87, 3.70, 7.38, 6.17)</td>\n",
       "      <td>text</td>\n",
       "      <td>Artificial intelligence (AI) based approaches ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'offset': 613, 'length': 1548}]</td>\n",
       "      <td>azure_document_intelligence</td>\n",
       "      <td>8.2639</td>\n",
       "      <td>11.6806</td>\n",
       "      <td>inch</td>\n",
       "      <td>(62.64, 266.40, 531.36, 444.24)</td>\n",
       "      <td>266.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-s2.0-S0927796X2030053X-am.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>(0.87, 6.23, 7.31, 6.60)</td>\n",
       "      <td>text</td>\n",
       "      <td>Keywords: Polymer Informatics; machine learnin...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'offset': 2162, 'length': 111}]</td>\n",
       "      <td>azure_document_intelligence</td>\n",
       "      <td>8.2639</td>\n",
       "      <td>11.6806</td>\n",
       "      <td>inch</td>\n",
       "      <td>(62.64, 448.56, 526.32, 475.20)</td>\n",
       "      <td>448.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          pdf_file  page              bounding_box  type  \\\n",
       "0  1-s2.0-S0927796X2030053X-am.pdf     1  (0.88, 0.21, 6.02, 0.54)  text   \n",
       "1  1-s2.0-S0927796X2030053X-am.pdf     1  (1.49, 1.52, 6.75, 1.73)  text   \n",
       "2  1-s2.0-S0927796X2030053X-am.pdf     1  (1.24, 1.97, 7.02, 2.82)  text   \n",
       "3  1-s2.0-S0927796X2030053X-am.pdf     1  (0.87, 3.70, 7.38, 6.17)  text   \n",
       "4  1-s2.0-S0927796X2030053X-am.pdf     1  (0.87, 6.23, 7.31, 6.60)  text   \n",
       "\n",
       "                                                text image_path   role  \\\n",
       "0  Version of Record: https://www.sciencedirect.c...       None  title   \n",
       "1  Polymer Informatics: Current Status and Critic...       None  title   \n",
       "2  Lihua Chenª, Ghanshyam Pilaniab, Rohit Batrac,...       None   None   \n",
       "3  Artificial intelligence (AI) based approaches ...       None   None   \n",
       "4  Keywords: Polymer Informatics; machine learnin...       None   None   \n",
       "\n",
       "   confidence                              spans                       source  \\\n",
       "0         NaN     [{'offset': 0, 'length': 130}]  azure_document_intelligence   \n",
       "1         NaN    [{'offset': 131, 'length': 59}]  azure_document_intelligence   \n",
       "2         NaN   [{'offset': 191, 'length': 412}]  azure_document_intelligence   \n",
       "3         NaN  [{'offset': 613, 'length': 1548}]  azure_document_intelligence   \n",
       "4         NaN  [{'offset': 2162, 'length': 111}]  azure_document_intelligence   \n",
       "\n",
       "   page_width  page_height page_unit                    normalized_box  \\\n",
       "0      8.2639      11.6806      inch     (63.36, 15.12, 433.44, 38.88)   \n",
       "1      8.2639      11.6806      inch  (107.28, 109.44, 486.00, 124.56)   \n",
       "2      8.2639      11.6806      inch   (89.28, 141.84, 505.44, 203.04)   \n",
       "3      8.2639      11.6806      inch   (62.64, 266.40, 531.36, 444.24)   \n",
       "4      8.2639      11.6806      inch   (62.64, 448.56, 526.32, 475.20)   \n",
       "\n",
       "   y_position  \n",
       "0       15.12  \n",
       "1      109.44  \n",
       "2      141.84  \n",
       "3      266.40  \n",
       "4      448.56  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## Page 1\\n\\nVersion of Record: https://www.sciencedirect.com/science/article/pii/S0927796X2030053X Manuscript_c681a8a49ed2ede90aaca95b72c753e1\\nPolymer Informatics: Current Status and Critical Next Steps\\nLihua Chenª, Ghanshyam Pilaniab, Rohit Batrac, Tran Doan Huanª, Chiho Kimª, Christopher Kuennethª, Rampi Ramprasadª,* aSchool of Materials Science and Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA b Materials Science and Technology Division, Los Alamos National Laboratory, Los Alamos, NM 87545, USA \"Center for Nanoscale Materials, Argonne National Laboratory, Lemont, Illinois 60439, USA\\nArtificial intelligence (AI) based approaches are beginning to impact several domains of human life, science and technology. Polymer informatics is one such domain where AI and machine learning (ML) tools are being used in the efficient development, design and discovery of polymers. Surrogate models are trained on avail- able polymer data for instant property prediction, allowing screening of promising polymer candidates with specific target property requirements. Questions regarding synthesizability, and potential (retro)synthesis steps to create a target polymer, are being explored using statistical means. Data-driven strategies to tackle unique challenges resulting from the extraordinary chemical and physical diversity of polymers at small and large scales are being explored. Other major hurdles for polymer informatics are the lack of widespread availability of curated and organized data, and approaches to create machine-readable representations that capture not just the structure of complex polymeric situations but also synthesis and processing condi- tions. Methods to solve inverse problems, wherein polymer recommendations are made using advanced AI algorithms that meet application targets, are being investigated. As various parts of the burgeoning poly- mer informatics ecosystem mature and become integrated, efficiency improvements, accelerated discoveries and increased productivity can result. Here, we review emergent components of this polymer informatics ecosystem and discuss imminent challenges and opportunities.\\nKeywords: Polymer Informatics; machine learning; deep learning; polymer design and discovery; polymer synthesis\\n\\n![](elements/table/page_1_Table_139697549724736.png)\\n\\n\\n```\\nIntroduction\\n* 2 Data generation, acquisition and management\\n\\t* 2.1 Scientific literature\\n\\t* 2.2 High-throughput and autonomous computational agents\\n\\t* 2.3 Hypothetical polymers\\n* 3 Polymer representation\\n* 4 Property prediction schemes\\n\\t* 4.1 Linear/Non-linear regression\\n\\t* 4.2 Multi-fidelity information fusion approaches\\n\\t* 4.3 Deep neural networks\\n\\t* 4.4 Polymer Genome online platform\\n```\\n\\nPreprint submitted to Materials Science and Engineering: R: Reports\\nSeptember 29, 2020\\n\\n## Page 2\\n\\n\\n![](elements/table/page_2_Table_139697549660368.png)\\n\\n\\n```\\n* 5 Polymer design algorithms\\n\\t* 5.1 Enumeration\\n\\t* 5.2 Sequential (Active) learning\\n\\t* 5.3 Evolutionary strategies\\n\\t* 5.4 Generative models\\n* 6 Application examples\\n\\t* 6.1 Polymer dielectrics design for high energy density capacitors\\n\\t* 6.2 Polymer membrane design for gas separation\\n\\t* 6.3 Polymer electrolytes design for Li-ion batteries\\n\\t* 6.4 Conducting polymers design for electronic applications\\n\\t* 6.5 Biodegradable and depolymerizable polymers discovery\\n* 7 Critical next steps\\n\\t* 7.1 Beyond homopolymers\\n\\t* 7.2 Sustainable data capture\\n\\t* 7.3 Polymer representation and learning\\n\\t* 7.4 Polymer retro-synthesis planning\\n\\t* 7.5 Autonomous integration of experimental and computational workflows\\n* 8 Acknowledgments\\n```\\n\\n1. Introduction\\nOver the course of less than a century, polymers have become pervasive in everyday life and high- technology [1-10]. Mass production of niche polymers, such as polyethylene, polypropylene and polystyrene, has outstripped the production scale of iron and steel, which have been the staple materials for millennia [11]. Different parts of the practically infinite chemical space of polymers display a dizzying variety of distinctive properties, which can be tuned exquisitely through control of their chemical and morphological structure [1, 2]. Extensive efforts have been devoted to searching the chemical space and tinkering with their structure and chemistry to optimize their properties for specific applications. Traditional intuition-driven and/or trial-and-error approaches have already revealed the promise that the polymer class of materials holds. Nevertheless, given the vastness of the chemical and structural space, new methods are required to effectively and efficiently search this space to identify optimal, application-specific solutions.\\nThe field of polymer informatics attempts to address this daunting search problem by the utilization of modern data- and information-centric approaches, inspired by emerging artificial intelligence (AI) and machine learning (ML) methods [12-19]. Polymer informatics efforts are seeing heightened activity and successes in recent years [19-25], but many of the ideas and concepts have gradually taken shape over a period of decades [19-21, 24, 26].\\nFigure 1 illustrates the essential elements of polymer informatics. The first vital ingredient is the polymer data, derived from experiments and (high-throughput) computations. Unlike hard materials, only limited well-organized/clean polymer data is available to be used for ML or AI-based techniques, e.g., in polymer handbooks [27] and online repositories [28]. Large volumes of experimental data remain trapped in the scientific literature, which is occasionally mined via laborious manual excerption. An emerging alternative approach is natural language processing (NLP) to continuously and dynamically extract polymer data, but significant future efforts are needed to effectively and accurately extract polymer data from literature. An- other important resource of polymer data is high-throughput computations using density functional theory (DFT) [29-31] and classical molecular dynamics (MD) simulations [32-39]. The recent development of au- tonomous computational agents, composed of machine learning modules and high-throughput computations, holds great promise for polymer data generation [40].\\n\\n## Page 3\\n\\n\\n![](elements/picture/page_3_Picture_139697557766784.png)\\n\\n*Figure 1: Essential elements of Polymer Informatics Ecosystem: 1) polymer data, derived from (high-throughput) computations and/or experiments (through manual or natural language processing-aided exception); 2) polymer representations, transforming polymers into numerical fingerprints and making it amenable to ML/AI models; 3) developing surrogate models for polymer property prediction and design polymers with desired properties for specific applications; 4) Online user interfaces provide easy and quick public access to the developed surrogate models and/or the underlying polymer data; 5) AI-aided computational and synthesis validation, feeding new information to existing polymer repositories.*\\n\\nThe second important component of polymer informatics is a suitable framework to create machine- readable polymer representations. Linear notations are commonly adopted to describe the chemical in- formation of polymers, for instance, using Simplified Molecular-Input Line-Entry System (SMILES) [41]. With SMILES as input, polymers are either directly fingerprinted using hierarchical polymer fingerprints [22, 23] or molecular fingerprints [42, 43] that are widely used in cheminformatics. Alternatively, optimal fingerprint representation (or latent knowledge) of polymers can be obtained using variational [44] or graph autoencoders [45, 46]. Designing fingerprints that fully capture not just the chemical and morphological information of polymers, but also how they were synthesized and processed is one of the most challenging parts of polymer informatics.\\nUsing the numerical polymer fingerprints and target property data as input, we move to the third part of the polymer informatics: polymer property prediction and design. In the former, various machine learning algorithms, e.g., non-linear regression [22], multi-fidelity information fusion [47, 48] and deep neural networks [43, 49], can be applied to learn the relationship between polymer fingerprints and their target property, resulting in a surrogate property prediction model for polymers. The developed surrogate model can instantly predict various properties of new polymers defined by the user. Another key benefit of the polymer informatics ecosystem is to accelerate the discovery of polymers with target properties for various applications. Several polymer design algorithms have been proposed, e.g., screening candidates based on the ML predicted properties from a huge list of enumerated polymers, iteratively selecting the next interesting polymer using active learning, and producing desired hypothetical polymers using genetic or generative deep learning algorithms. These design approaches have significantly accelerated the polymer design process for capacitors [50-52], membrane separation [42], organic solar cells [53], among others.\\nOnce the desired polymer candidates are proposed, the next step is to validate the polymers via com- putational methods and physical synthesis. The former is manageable using AI-automated data generation agents that control computational workflows (but are applicable to only those properties that are accessible through computations). The latter is a challenge, as the synthesis of the selected polymer candidates is not\\n\\n## Page 4\\n\\nstraightforward. Chemical reactions, precursors, reagents and processing conditions (temperature, pressure and solvents) must be identified for each polymer to successfully synthesize them. Attempts are being made to expedite this process by using AI-assisted synthesis planning and robotic/autonomous (retro)synthesis. Although computer-aided synthesis design for molecules was recently accomplished [54, 55], there remains lots of scope and challenges for polymer synthesis planning, which is expected to blossom rapidly in the next several years. Moreover, the data obtained from these synthesized polymers and/or from their computations can be added into existing polymer repositories to re-optimize ML models and re-design or re-imagine the next experiments.\\nIn this paper, we review these emergent components of the polymer informatics ecosystem and discuss imminent challenges and opportunities. In Section 2, we discuss protocols available for polymer data genera- tion, acquisition and management. It is followed by a survey of various schemas for polymer representations in Section 3. Next, we move on to review machine learning algorithms utilized and adapted for polymer property prediction (Section 4) and design for various applications (Section 5). We then list several repre- sentative application examples that have benefited and may benefit from the polymer informatics philosophy in Section 6 and identify critical next steps that the community will need to address and surmount in the near future in Section 7.\\n2. Data generation, acquisition and management\\nThe central tenet of polymer informatics is that if a sufficient volume of polymer data can be ap- propriately generated or curated, it can facilitate discovery/design of functional polymers with targeted performance. Below we discuss how polymer data can be accumulated from the literature or generated using high-throughput and autonomous computations.\\n2.1. Scientific literature\\nA reliable and enormous data resource for polymer data is the scientific literature, including printed handbooks [56-59], online repositories [28] and journal articles. As listed in Table 1, polymer handbooks, such as the Polymer Handbook [56] and Properties of Polymers [58], are introductory materials containing chemical, property and synthesis information on polymers. More recently, several polymer databases have been digitalized, allowing for easy access to polymer data. A few representative databases include PoLyInfo supported by the National Institute for Materials Science of Japan (NIMS) [28], CROW Polymer Property Database [60], Polymers: A property database [61], CAMPUS [62], LANDOLT-BORNSTEIN [63] and Polymer Property Predictor and Database (NIST) [64]. In contrast to the field of inorganic materials, only a few computation-based property databases for polymers are available. This can be attributed to the high computational complexity of polymers due to their complicated physical and chemical structures. A good example of a database of computational data polymers is Khazana [65], which includes DFT computed band gap, dielectric constant, refractive index and charge injection barriers. The third important resource of polymer data is the ever-increasing corpus of published journal articles.\\nTimely dynamical extraction of polymer data from the literature in a machine-readable format can be challenging and is achieved using either the laborious manual excerption and/or machine-learning methods usually classified as NLP. Manual text excerption refers to the old-fashioned procedure of collecting data from the literature and entails laborious efforts for data extraction, validation, and normalization owing to the absence of standard journal policies for publishing polymer data. Nonetheless, researchers have painstakingly collected important information on polymer types, their chemical structures (repeat units), names and class, their properties (e.g., physical, thermal, mechanical, dielectric, physicochemical and solution properties), and their synthesis recipes (e.g., polymerization paths, reactants and reagents) [28, 56-59]. Crucially, easy access to the resulting databases has been provided through online repositories, as discussed earlier.\\nMachine learning-based NLP has emerged as an alternative approach for information excerption from the literature in the last few years. NLP can be used to automatically scan the literature corpus and extract relevant polymer properties, which can be organized in a tabular fashion based on the NLP model predicted text relations. The use of NLP in materials science is still in its infancy, due to the difficulty\\n\\n## Page 5\\n\\nTable 1: Available polymer data resources\\n\\n![](elements/table/page_5_Table_139697557805808.png)\\n\\n\\n```\\n\\\\begin{tabular}{l l l} \\\\hline Source & Name & Data type \\\\\\\\ \\\\hline Handbook & Polymer Handbook [56], Handbook of Polymers [57], & Empirical \\\\\\\\  & Properties of Polymers [58], Polymer Data Handbook [59] & Empirical \\\\\\\\  & Polymer synthesis: theory and practice[66] & Empirical \\\\\\\\ \\\\hline Online Repositories & PoLyInfo [28] & Empirical \\\\\\\\  & CROW Polymer Property Database [60] & Empirical \\\\\\\\  & Polymers: A property database [61] & Empirical \\\\\\\\  & CAMPUS [62] & Empirical \\\\\\\\  & LANDOLT-BORNSTEIN [63] & Empirical \\\\\\\\  & Polymer Property Predictor and Database (NIST) [64] & Empirical \\\\\\\\  & Khazana [65] & Computational \\\\\\\\ \\\\hline Published journal articles & Various & Empirical/Computational \\\\\\\\ \\\\hline \\\\end{tabular}\\n```\\n\\nin interpreting technical languages and incorporating domain knowledge. It is further complicated by the absence of standard journal policies for publishing scientific data. Several initial attempts have tried to use NLP to collect materials synthesis recipes, capture latent knowledge and to even predict potentially superior thermoelectrics [18, 67, 68]. These successes motivate the further application of NLP in polymer informatics, such as the extraction of properties, synthesis recipes or processing conditions from past literature. Despite initial success, many unique challenges are posed in the case of polymers, for example, non-uniform polymer names. More details are described in Section 7.\\n2.2. High-throughput and autonomous computational agents\\nHigh-throughput computations using first-principles theory and classical MD are important approaches to amass polymer data. However, this task is non-trivial because of the enormously complicated chemical and physical structures of polymers at the atomic scale; polymers usually display either amorphous or semi- crystalline phases. Given the expensive computational cost of first-principles computations, small length- scale models (< 100 atoms) have been developed to represent polymers and approximate their physical, electronic and dielectric properties [29-31, 40, 51]. The computed results, however, generally suffer from certain accuracy issues depending on the methodology. To model polymers in the large-scale, classical MD with empirical force fields have been applied to study the structural dynamics [69-76] and diverse properties (e.g., dielectric, thermal, mechanical and ion transport properties) [32, 34, 35, 37, 38, 71, 77-82] of polymers. However, such parameterization schemes are also restricted by the availability of force fields and the high computational cost to simulate very large systems (> thousands of atoms).\\nBalancing the trade-off between cost and accuracy, past efforts have led to the computation of the elec- tronic, dielectric and optical properties (such as band gap, charge injection barriers and dielectric constant) of thousands of polymers using DFT [29-31, 40, 83]. A hierarchy of models, i.e., single-chain, pure crystal and amorphous, has been developed to represent realistic polymers, as shown in Figure 2a). The simplest single-chain model is composed of only a chain of monomers in vacuum, while crystal and amorphous models represent the crystalline and amorphous regions of polymers, respectively. In spite of this simplification, the creation of correct low-energy crystalline structure of a polymer, especially for novel polymers, remains a major challenge [40]. To address this issue, Huan et al. developed a general computational workflow, referred to as polymer structure predictor (PSP), to predict crystal structures of linear polymers. In this workflow, a polymer is defined in terms of its chemical composition and atomic connectivity, using the SMILES notation (more details in Section 3). Reasonable single-chain and crystal models of the polymer can be predicted/created [40] using this scheme. Such efforts have led to formation of the largest dataset for polymers using computations, which can be accessed from https://khazana.gatech.edu. Some of the important computed properties include the crystal band gap, single-chain band gap, charge injection barri- ers, atomization energy, ionization energy, electron affinity, dielectric constant and refractive index [29, 40]. Other researchers have spent extensive efforts on estimating thermal conductivity [78, 79, 84, 85], Young\\'s\\n\\n## Page 6\\n\\n\\n![](elements/picture/page_6_Picture_139697557827056.png)\\n\\n\\n![](elements/picture/page_6_Picture_139697557826288.png)\\n\\nFigure 2: a) Hierarchy of models to represent polymers, i.e., single-chain, pure crystal and amorphous phases. This figure is taken from Ref. [40] with permission from ACS Publications. b) Autonomous computational agents to generate polymer data. c) Design of hypothetical polymers using the BRICS scheme, along with some common polymer building blocks. \\'*\\' represents the possible linking position for each building block.\\nmodulus [82], tensile strength [34, 80, 81], and the lithium conductivity [33, 36, 37] of representative poly- mers using classical MD simulations. However, it is still challenging to compute these properties for a diverse range of polymers, especially those that have not been studied well.\\nGiven the vast chemical space of polymers, a new strategy aided by an autonomous computational agent has been developed to dynamically select the next-candidate polymer with target properties [40]. As visualized in Figure 2b), by utilizing the available (seed) computational dataset, machine-learning models are developed with the capability to instantly predict target properties for a large number of new polymers. Candidate polymers that meet the desired properties are selected, followed by a \"3D structure\" conversion step (involving generation of hierarchical models as shown in Figure 2a)). The newly created structures are then modeled using high-throughput calculations, and the obtained results are added to the seed dataset iteratively. This autonomous platform is applicable for single or multiple polymer property predictions, and offers an efficient way to discover/design polymers with desired performances.\\n2.3. Hypothetical polymers\\nData derived from experiments or the computations mentioned involve only known polymers. But how can we expand and explore beyond the known polymer chemical space? Variations of this question have already been tackled by different communities within chemical and materials sciences, such as drug discovery, inorganic solid state, metal-organic frameworks, 2D materials, etc., by exploiting various theoretical tools to construct databases of hypothetical molecules (e.g. ZINC) or materials (e.g. Materials Project). Further, computational tools, such as first-principles or classical methods, have been employed to estimate properties of these hypothetical cases, and screen promising candidates for future synthesis efforts. Some databases\\n\\n## Page 7\\n\\neven estimate the synthesizability of a candidate using multiple models (e.g., based on free energy, synthetic accessibility scores, etc.) to ensure only realistic and plausible candidates are included. The successes of such molecule/materials databases are inspiring the creation of similar libraries for polymers.\\nIn this regard, Batra et al. [44] devised an approach to explore the vast unknown chemical polymer space by generating new, but realistic, hypothetical polymers. As illustrated in Figure 2c), they first obtained SMILES representation of ~ 12,000 polymers successfully synthesized in the past. Next, using the concepts of breaking of retrosynthetically interesting chemical substructures (BRICS) [86, 87], polymer \"building blocks\" - each with two or more chain ends denoted by symbol [*], e.g., [*] c1ccc ( [*] ) cc1, [*]C(=0) [*], [*] CC [*] - were obtained along with their frequency of occurrence. Following this, hypothetical polymer SMILES strings were created by combining (at the [*] location) various numbers of building blocks, ranging from 2 - 7, resulting in a total of ~ 250,000 hypothetical polymers. This approach can be extended to create nearly infinite polymer candidates that may later be used to screen target properties. Care is taken to preserve the frequency of occurrence of different building blocks, making the constructed hypothetical SMILES dataset realistic and representative of the initial collected empirically known polymers. Moving forward, different chemical constraints or block neighbor restrictions can be introduced to limit the possible combination of building blocks, and generate more realistic/synthesizable polymers.\\n3. Polymer representation\\nOnce the polymer structural, chemical, property and synthesis data are collected from the aforementioned resources, it should be processed/transformed to make it amenable to AI/ML based methods. Depending on the target polymer property or the input data type, different polymer representations may be chosen. Below, following a short discussion on the group contribution method, we discuss some of the more recent and successful polymer representation methods.\\nThe group contribution technique developed by Van Krevelan and coworkers assumes that a polymer property can be estimated as a weighted sum of contributions arising out of its constituting fragments (referred to as quantitative structure-property relationships (QSPR) fingerprints) [88]. Using this and sub- sequent variations of this method, models describing a range of polymer properties have been developed with/without machine learning, including glass transition temperature, dielectric constant, refractive index, electrical conductivity, thermal conductivity, gas and aqueous diffusion, and intrinsic viscosity [88-91]. How- ever, the developed models rely on the available fragment library and have little predictive capabilities for new polymers containing chemical fragments outside this pre-defined library.\\nTo efficiently encode chemical information of molecules into machine-readable format, line notations have been designed to describe molecules using a line of text strings. Examples of such approaches include SMILES, the Wiswesser line notation (WLN), SYBYL Line Notation (SLN) and IUPAC International Chemical Identifier (InChi). SMILES is one of the most popular methods to represent molecules, because it is both human-readable and machine-friendly [41]. Further, various molecular fingerprinting algorithms have been developed to transform SMILES of small molecules into numerical vectors. Avalon, Daylight and Extended-Connectivity [93] fingerprints are examples of common fingerprinting algorithms that can be accessed through the open-source RDkit library [87]. Within these fingerprints, the presence or absence of substructures within a molecule is encoded into binary vectors, which can be used as inputs to data-driven models. SMILES representations of molecules can also be utilized (or transformed as graphs) in generative neural networks for fingerprint learning and molecular generations [46, 46], but can also be directly used as input language in text-based machine learning algorithms [94, 95]. The use of SMILES and similar line notations for molecules has transformed data-driven research in chem- and bio-informatics.\\nIn contrast to small molecules, polymers are macromolecules composed of many repeat units, and require unique ways to capture their structural information. As illustrated in Figure 3a), in modern data-driven models, SMILES of oligomers with several repeat units (< 5) have been applied to represent polymers, which can be fingerprinted using regular molecular fingerprinting algorithms [42, 43, 85]. The ML models developed using such oligomer fingerprints can predict various properties of polymers fairly well, although the effect of polymer morphology on the target property is excluded. In a similar development, modified SMILES representations for polymers have been developed which represent endpoints or connection points\\n\\n## Page 8\\n\\na) SMILES Representation\\n\\n![](elements/picture/page_8_Picture_139697601688432.png)\\n\\nFigure 3: Polymer representations: SMILES and BigSMILES [92]. Using the input of SMILES, molecular [42] and hierarchical polymers fingerprints [22, 23] were developed to numerically represent polymers.\\nof repeat units using special symbols. For example, polyethylene is represented as [*]CC[*], where CC is the repeat unit of polyethylene and * represents the connecting points between repeat units [22, 23]. Furthermore, a hierarchy of hand-crafted fingerprints for polymers have been developed to capture the connectivity and morphology information of polymers in order to improve the property prediction accuracy [22, 96-99]. Figure 3a) shows details of the hierarchical fingerprint, including the (1) atomic-level, (2) block- level, and (3) chain-level components. At the atomic-level, the number fraction of atomic-level fragments within the polymers, defined by the generic label \"A¿BjCk\", are considered. The block-level fingerprint components are the number fraction of pre-defined building blocks that constitute the polymers, such as C6H4, C=O, CH2 and CO. Chain-level features capture information at the morphological scale, including the length of the longest or shortest side chains with or without rings. Further, QSPR fingerprints, such as the volume to surfaces ratio and van der Waals surface area, are also considered. Using this approach, models to predict many properties of polymers have been developed, including band gap, glass transition temperature and dielectric constant [22, 23]. Detailed examples are provided in Section 4.\\nAdditionally, BigSMILES has been recently developed for describing macromolecules, e.g., homo-and co-polymers [92]. It is an extension to SMILES, expressed as {RepUnit1, RepUnit2, RepUnit3, ... }. Here, RepUnit1, RepUnit2, RepUnit3 are a list of (same or different) repeat units within polymers, with random positions. For example, Poly(ethylene-co-propylene) is denoted by {CC, CC(C) }, as shown in Figure 3b). In this representation, branched, network and terminal group information of polymers may be also incorporated. However, there are no available fingerprinting algorithms to transform BigSMILES into numerical vectors yet.\\nMolecular structures can also be represented as a graph via an input of SMILES, where atoms and bonds are represented by nodes and edges, respectively. Such a method has been widely utilized for molecular structure generation and property prediction in cheminformatics, bioinformatics and materials science with great success [100-104]. Since it is challenging to use graphs to represent polymers, due to its large- scale morphology, researchers have attempted to use oligomers (including less than 5 repeat units) to label\\n\\n## Page 9\\n\\n\\n![](elements/picture/page_9_Picture_139697601850912.png)\\n\\n*Figure 4: a) Gaussian process regression (GPR) model to learn the correlation between fingerprints and target property, providing predicted values and uncertainty (shaded regions). b) Multi-fidelity (MF) co-kriging approach depends on two models: the Gaussian processes \\\\(Z_{\\\\mathrm{LF}}(\\\\mathbf{x})\\\\) of the low-fidelity (LF) function mapping the fingerprint space and low-fidelity property (\\\\(\\\\mathrm{y}_{\\\\mathrm{LF}}\\\\)) and the Gaussian processes \\\\(Z_{\\\\mathrm{d}}(\\\\mathbf{x})\\\\) to map the fingerprint space and difference between the low-fidelity and the high-fidelity (HF) functions. The property prediction at the high-fidelity level (\\\\(Z_{\\\\mathrm{HF}}(\\\\mathbf{x})\\\\)) is \\\\(Z_{\\\\mathrm{HF}}(\\\\mathbf{x})=\\\\rho Z_{\\\\mathrm{LF}}(\\\\mathbf{x})+Z_{\\\\mathrm{d}}(\\\\mathbf{x})\\\\), where \\\\(\\\\rho\\\\) is a scaling factor that quantifies the correlation between the two fidelities of data. c) General Neural network workflow, including input, hidden and output layers.*\\n\\npolymer graphs with atom-based or substructure/motif based-methods [45, 46, 105]. Motifs refer to larger size substructures. However, because monomers of many polymers are large and complicated, this leads to monomer generation failures using small substructures. Further, polymers are composed of large numbers of monomers, and it is not clear how one can incorporate large-scale morphological information as graphs. These critical issues are discussed in Section 7.\\n4. Property prediction schemes\\nThe selection of suitable learning algorithms to map polymer fingerprints and properties is a critical step. Depending on the complexity of the target property, the volume and the nature of the available datasets, various learning algorithms have been applied, such as linear or non-linear regression algorithms, multi-fidelity information fusion and deep neural networks.\\n4.1. Linear/Non-linear regression\\nThe linear regression algorithm assumes that the property being modeled is a linear function of the fingerprints, which is the simplest method to build machine learning models. For polymers, various property prediction models have been developed using group contribution methods [88], multiple linear regression [89, 90], and least-squares regression [21, 107, 108], with QSPR or quantum-chemical fingerprints. These models are limited by the neglect of the non-linear relationships between polymer fingerprints and their properties. To overcome this issue, non-linear regression algorithms have been employed, such as support vector machine (SVM), kernel ridge regression (KRR) and Gaussian process regression (GPR). For instance, Yu et al. used SVM to train glass transition prediction models using QSPR fingerprints and experimental property values [89, 109], while KRR has been applied to develop models for a series of high-throughput computed polymer properties (e.g., band gap and dielectric constant) [110].\\nIn recent years, the GPR algorithm has been broadly utilized to build machine learning models for poly- mer property prediction [22, 23, 42, 52, 111]. As illustrated in Figure 4a), the key advantage of GPR is that predicted uncertainties are provided by learning a generative and probabilistic distribution with the mean representing the prediction and the confidence interval estimating the uncertainty. Figure 5a) illustrates four representative GPR models, including chain band gap, glass transition temperature, frequency-dependent dielectric constant and gas permeability. These models were trained using 3881 DFT computed, and 5076, 1193 and 1779 experimental values, respectively. 5-fold cross-validation (CV) was employed to avoid model\\n\\n## Page 10\\n\\n\\n![](elements/picture/page_10_Picture_139697557827392.png)\\n\\n*Figure 5: a) Parity plots of GPR predicted and true values of the glass transition temperature, band gap of sing-chain polymers, dielectric constant and gas permeability. In the case of the gas permeability model, 6 gases, i.e., O\\\\({}_{2}\\\\), N\\\\({}_{2}\\\\), CH\\\\({}_{4}\\\\), He, CO\\\\({}_{2}\\\\) and H\\\\({}_{2}\\\\), were considered and dielectric constant at 9 different frequencies was used in the dielectric constant model. CV-test RMSE is the average RMSE of the test subsets in 5 fold-CV [23]. Error bars represent GPR uncertainty. b) A comparison of learning-curves for the GPR and multi-fidelity (MF) predicted band gap [48] and tendency to crystallize [106]. c) Neural network-based solvent prediction accuracy of soluble (top) and insoluble (bottom) polymers for 24 solvents, including non-polar, polar-aprotic and polar-protic solvents, along with results from GPR models trained by Hildebrand parameters [49]. Figure a), b) and c) are taken from Ref. [23], Ref. [48, 106] and Ref. [49], respectively, with permission from ELSEVIER and ACS Publications.*\\n\\n\\n## Page 11\\n\\noverfitting. R2 and RMSE denote the coefficient of determination and the root-mean-square error, respec- tively. RMSE100% and RMSECV, test respectively denote the RMSE errors on the whole dataset used for model training or on the test subset during 5 fold-CV. In the case of the gas permeability model, 6 gases, i.e., O2, N2, CH4, He, CO2 and H2, were considered and numerically represented using one-hot encoding. Likewise, in the dielectric constant model the frequency value (at 9 different frequencies) was used as a fea- ture to obtain a frequency-dependent dielectric constant model. We note that the developed GPR models exhibit very high R2 and acceptable RMSECV, test with respect to the wide property range of the training datasets. Additionally, the performance of these models has been further validated by using systematic analysis, involving the effect of feature reduction, various levels of train-test splits (i.e., learning curves) and validation on completely unseen datasets.\\nThe GPR algorithm can be used to build accurate and reliable ML models for a single property while also providing prediction uncertainties. However, the GPR method has two issues: 1) it requires a manageable dataset size. Large datasets (> 5000) become prohibitively expensive to train. 2) It does not have the capability to train multiple properties in one single model. Therefore, more advanced algorithms have been utilized to improve these issues, such as multi-fidelity information fusion and deep learning methods as discussed below.\\n4.2. Multi-fidelity information fusion approaches\\nIt is quite common to encounter problems where several datasets have varying levels of accuracy, data generation cost and noise levels are present. Typically, the most precise experimental measurements (or computations) also tend to be the most time and resource intensive, the so-called high-fidelity (HF) data. However, polymer properties of interest can also be estimated via cheaper methods at lower accuracy. For instance, empirical trends, simple group-contribution methods and computationally demanding quantum mechanical simulations can generate this low-fidelity (LF) data. Given such a situation, a multi-fidelity (MF) information fusion model aims to consolidate all the available information from the varying fidelity sources to make the most accurate and confident property predictions at the highest level of fidelity [47, 48, 112-116]. Comparative studies have shown that the multi-fidelity approach performs better than any single-fidelity based method in terms of prediction accuracy, especially for small (high-fidelity) data sets. Typical strategies for MF learning are discussed in Ref. [47]. Among them, the Gaussian processes-based co-kriging regression method [117] is viewed as a powerful method and has been utilized to predict polymer properties, such as band gap and degree of crystallinity [48, 118]. As shown in Figure 4b), this MF approach is composed of two models: the Gaussian processes ZLF (x) of the low-fidelity function and the Gaussian processes Za(x) related to the difference between the low-fidelity and the high-fidelity functions. The property prediction at the high-fidelity level (ZHF(x)) is ZHF(x) = pZLF(x) + Za(x). Here, p is a scaling factor that quantifies the correlation between the two fidelities of data.\\nFigure 5b) shows two successful examples of MF approaches being applied to polymer property pre- dictions [48, 106], i.e., the tendency to crystallize and the band gap. For the former, a MF model was trained using 107 high-fidelity data directly measured by experiments and 429 low-fidelity data estimated using a combination of experimental and group-contribution methods. In the latter, 382 hybrid and PBE computed band gap values were used as high- and low-fidelity data in the MF model. Figure 5b) compares the learning performance of the MF models against single-fidelity GPR models trained on the respective high-fidelity polymer property data, i.e., the RMSE on the training and the test set as a function of the training size of the high-fidelity data. We note that MF models surpass the GPR model accuracy (trained on the high-fidelity data alone) at a much smaller fraction of the high-fidelity training data. This is mainly because the relatively large volume of the low-fidelity data, although somewhat inaccurate, allows the MF model to learn polymer property trends. These findings indicate that there are benefits to employing the MF approach, especially in situations wherein resource demanding high-fidelity experimental data can be combined with a large number of low-fidelity and inexpensive computational data.\\nWhile the first proof-of-principle examples are just beginning to appear, MF models could have a consid- erable impact in the field of polymer informatics. It is worth pointing out that the accuracy of MF models depends on the ability of the shared subset of high- and low-fidelity data to learn the latent space of the two fidelities. Further, there is a necessity to improve upon the MF scheme. For instance, several levels\\n\\n## Page 12\\n\\nof fidelity hierarchies can be present simultaneously in the polymer property datasets. The number of the co-kriging model parameters can significantly increase in such scenarios, leading to expensive computational cost. Consequently, advanced MF learning algorithms should be developed to speed up the learning process, particularly when several levels of fidelities are present in the polymer data sets.\\n4.3. Deep neural networks\\nConventional machine learning techniques described above provide good property prediction accuracy. However, these methods are computationally efficient for systems with small dataset size only. Given the surge in the available computational/experimental data in materials science, deep neural networks (NN) are being increasingly utilized in polymer informatics. Figure 4c) presents the general architecture of NNs, in which molecular or polymer fingerprints form the input layer. The following hidden layers are constructed with a specific activation function, e.g., the parametrized rectified linear unit (PReLU). The final output layer of the NN consists of neuron(s) for target properties, also with a specific activation function depending on the problem at hand (classification or regression). The details of various types of NNs and their uses in materials science are well-reviewed in Refs. [119-121]. Below we discuss the initial attempts to apply NNs for polymer properties prediction [43, 49, 122-125].\\nThe selection of suitable polymer-solvent pairs is a critical step for polymer synthesis. Chandrasekaran et al. have developed a deep neural network model for solvent prediction [49]. In this work, 4,595 polymers and 24 solvents, forming a total of 11,958 polymer + good-solvent pairs and 8,469 polymer + non-solvent pairs, were used to train a binary classification NN model (i.e., given a polymer-solvent pair the model predicts if it a good-solvent or non-solvent for that polymer). A multilayer perceptron with special architecture was used: the first part of the NN composed of two input branches, one for the polymer descriptors generated using hierarchical fragment-based fingerprint described in Section 3 and the other for the solvent descriptors represented by one-hot encoding. In the second part, polymer and solvent latent space were concatenated into a single merged latent vector. Figure 5 c) shows the neural network prediction accuracy of soluble (top) and insoluble (bottom) polymers for 24 solvents, including non-polar, polar-aprotic and polar-protic solvents. Performance results for the GPR models trained using Hildebrand parameters of about 100 polymers [118] are also compared. In general, the performance of the NN model greatly outperforms that of the GPR model, mainly due to the higher level of diversity in the training data. Further, the Hildebrand parameter is only an approximate empirical approach to distinguish good-solvent against non-solvents, based on the notion of \"like dissolves like\". This deep neural network-based framework provides a more general, accurate, and efficient way to predict good-solvents vs. non-solvents for new polymers.\\nAdditionally, researchers have applied NNs to build prediction models for glass transition temperature [122-124], polymer permeability to gases [91] and thermal conductivity (k) of polymers [43, 85, 125]. For the glass transition temperature and polymer permeability, small datasets ( <= 150 polymers) were applied to train NNs, raising concerns on the generality of obtained models for new cases. In the case of K, Zhu et al. have used classical MD computed k values of single-chain polymers and molecular fingerprints to train the NNs models. One potential concern is that the computational uncertainty, arising from the model difference between the adopted single chain and realistic polymers, may introduce additional noise in the ML models [85]. An alternative approach is to directly use experimental « to train the model, although, only sparse data is available. To overcome this issue, Wu et al. [43] has utilized the transfer learning approach to learn the k of polymers (58 data points), via training other properties of polymers with large data size (e.g., melting temperature, glass transition temperature and heat capacities). The performance of the obtained model is better than those trained only on the thermal conductivity data, because the shared features between k and other properties and large training dataset are considered in the transfer learning algorithm. However, there are still challenges, as discussed in Section 7.\\n4.4. Polymer Genome online platform\\nSignificant efforts are also being made to provide easy access to the aforementioned polymer prediction models. In this regard, the Polymer Genome online platform (www.polymergenome.org) has been developed to instantly provide property predictions for polymers. As summarized in Figure 6a), various polymer\\n\\n## Page 13\\n\\n\\n![](elements/picture/page_13_Picture_139697573414128.png)\\n\\n*Figure 6: a) Summary of various property prediction models implemented in the Polymer Genome online platform (www.polymergenome.org). RMSE(CV) denotes the average RMSE errors on the test subset during the 5 fold-CV. b) Overview of the Polymer Genome platform. Polynorbornene is used as an example of user input to show the obtained ML predicted properties and 3D structure visualization.*\\n\\nproperty prediction models have been implemented, including electronic, dielectric, thermal, mechanical and other important properties. The source and size of the training data, the applied algorithms and the expected errors (RMSEcv) for each of the property models are also provided. Figure 6b) shows a typical output of Polymer Genome, taking the example of Polynorbornene. The SMILES ([*]C=CC1CCC([*]C1)), which forms the repeat unit of Polynorbornene, is provided as the input to Polymer Genome, where [*] denotes the connection points of the repeat units. ML predicted properties of this polymer are shown in a tabular format. The 3D visualization of the structure with atomic coordinates is also provided at the bottom of the page. More detailed information is available in Ref. [22, 23].\\n5. Polymer design algorithms\\nOnce the polymer surrogate models are trained, they can be utilized to accelerate the polymer discovery process. Below we outline two distinct strategies for this. While the first relies on screening candidates that meet target property requirements based on predictions for a pre-determined candidate pool, the other utilizes genetic and generative models to directly produce desirable candidates.\\n5.1. Enumeration\\nOne of the dominant applications of machine learning techniques is to significantly accelerate the ra- tional design and discovery of new materials by efficiently searching a pre-determined chemical space. The previously discussed ML models are used to predict the properties of a large pool of candidate polymers enumerated based on some physically or chemically motivated scheme, followed by a down-selection pro- cedure based on certain screening criteria. The end result is a rank-ordered list of promising candidates for the target application. The initially enumerated candidates may be previously synthesized polymers, or hypothetical polymers made by human experts or machine (e.g., genetic algorithm). Figure 7a) shows the\\n\\n## Page 14\\n\\ntrends, in a form similar to \"Ashby plots\", of various ML predicted properties (such as glass transition tem- perature, band gap, dielectric constant (at THz) and density) for ten-of-thousands of known/synthesizable polymers. These synthesized polymers have been manually accumulated from various resources, as discussed in Section 2. Depending on the property requirements for specific applications, different combinations of properties can be selected. For instance, polymers that are tolerant to extreme temperatures require large band gap, high glass transition temperature and dielectric constant, whereas polymers electrolytes used in Li-ion batteries require desired electron affinity, band gap, and ionization energy. Polymer membranes, on the other hand, require suitable gas permeability-selectivity pairs.\\n\\n![](elements/picture/page_14_Picture_139697557804080.png)\\n\\n*Figure 7: a) ML predicted properties of ten-of-thousands of enumerated known/synthesizable polymers. Different combinations of properties can be selected to screen polymers for the specific application, for example, large band gap, high glass transition temperature and dielectric constant for polymers tolerant to extreme temperature and electric field. b) Sequential (active) learning workflow (left) and its use for polymer design (right): number of experiments required (on average) to discover 1 — 10 polymers with glass transition temperature greater than 450 K when starting with an initial dataset size of five polymers. The average is calculated using 50 different runs and the standard deviation is denoted by the error bar. This figure is taken from Ref. [126] with permission from Cambridge University Press.*\\n\\nFollowing this forward design pipeline, Mannodi Kanakkithodi and co-workers identified promising poly- mer dielectrics with desired dielectric constant and band gap from a series of human-designed hypothetical polymers, made up of 4, 6 and 8 building blocks (e.g., -CH2-, -CO-) [51]. Likewise, Chen et al. proposed five representative polymer candidates satisfying high glass transition temperature and required dielectric\\n\\n## Page 15\\n\\nconstant for high temperature, energy density capacitors and microelectronic devices from a pool of syn- thesized polymers [52]. Additionally, Wu et al., on the other hand, used a surrogate thermal conductivity model based on transfer learning to screen promising candidates with target glass transition and melting temperatures, resulting in the synthesis of polymers with thermal conductivities of 0.18 - 0.41 W/mK [43]. Another successful example is from Kumar [42], wherein two polymer membranes with excellent CO2/CH4 separation performance were discovered from over 11,000 homopolymers, guided by GPR based gas perme- ability prediction models. These findings strongly advocate the success of machine learning assisted forward design approach to discover polymer candidates for specific applications.\\n5.2. Sequential (Active) learning\\nThe polymer design algorithms discussed above provide a subset of promising polymer candidates with tailored properties for further validation via experimental synthesis or high-fidelity computations. However, these models are passive, with inherent errors in the property predictions owing to the limitations, such as bias or limited size of the training data. Thus, how one can dynamically and efficiently optimize polymers for the next experiment (or computation) is an important problem in materials discovery. It is far from trivial to select optimal candidates based purely on human intuition. In recent years, active-learning algorithms that exploit Bayesian optimization frameworks have been developed to effectively guide experiments or high-throughput computations for materials design, e.g., optimizing GaN LED structures, BaTiO3 based piezoelectrics, and other inorganic materials for thermoelectric and electronic devices [127].\\nAs illustrated in Figure 7b), active learning algorithms consist of three important components: 1) a surrogate model for the target property prediction; 2) an acquisition function to select the optimal point for the next experiment; 3) addition of the newly performed experiment to the knowledge dataset [126, 127]. The surrogate models in part 1) can be trained using various algorithms introduced in Section 4. To provide both prediction and uncertainty values of the target property, Gaussian process-based algorithms are common approaches used in active learning. There are other methods, such as support vector regression or decision trees in combination with bootstrapping methods, that estimate both the target property and its uncertainty. In part 2), the user can search unlabeled data by either using the prediction uncertainties (called exploration), or by maximizing the target prediction values (called exploitation), or by balancing between exploration and exploitation. In the last part, the newly generated data from the new experiment is supplemented into the knowledge dataset to retrain the surrogate model. The whole pipeline is repeated until the target candidate is achieved.\\nIn the polymer domain, Kim et al. benchmarked the use of active learning to efficiently search polymers with Tg > 450 K [126]. Figure 7b) illustrates the average number of experiments required to discover 1 - 10 polymers with a glass transition temperature of above 450 K, starting from an initial training dataset of 5 polymers. The error bars denote the standard deviation across the 50 different runs. We note that on average 30, 46, 98 and 234 experiments were required to discover 10 high-glass transition temperature polymers using acquisition function definitions based on balanced exploitation and exploration, exploitation, exploration and random approaches, respectively. These findings indicate that the balanced exploitation and exploration method showed the best performance in terms of discovering promising polymer candidates. Additionally, Huan et al. have applied the active learning to automatically select polymer candidates for high-throughput DFT computations and find polymer dielectrics with a large band gap. More details are shown in Section 5. It is evident that the integration of active-learning within the materials discovery pipeline can guide materials design and dataset expansion in an efficient and targeted fashion.\\n5.3. Evolutionary strategies\\nAnother approach to polymer discovery is the \"inverting the prediction pipeline\". Contrary to the enumeration approach that relies on virtual screening of polymers from a pre-defined candidate set using instantaneous property prediction from surrogate models, inversion problems focus on directly generating polymers that satisfy given property objectives, making it a more general approach to materials discovery. Two approaches for direct materials design have emerged: first, the use of evolutionary methods, such as the genetic algorithm (GA) [128, 130], and second, generative ML approaches, such as variational autoencoders\\n\\n## Page 16\\n\\n\\n![](elements/picture/page_16_Picture_139697601847456.png)\\n\\n*Figure 8: Polymer inverse design using machine learning. Use of evolutionary algorithms, such as GA, for design of polymers with target properties; a) basic operations of crossover and mutation to generate polymer offsprings, taken from Ref. [128] with permission from ELSEVIER Publications; b) the different stages of the iterative evolutionary process, involving population of new candidates, evaluation of fitness function using property-prediction models, and selection of the next generation with best fitness, taken from Ref. [129] with permission from ACS Publications; c) results for an exemplary polymer design problem of high glass transition temperature and large band gap, taken from Ref. [128] with permission from ELSEVIER Publications; d) Use of variational autoencoders (VAE) for polymer design. The latent space is searched to find polymers with desired properties, which are ‘generated’ using the decoder mapping.*\\n\\n(VAE) [131] and generative adversarial networks (GAN) [132]. We describe the evolutionary approaches here, while generative methods are discussed in Section 5.4.\\nGA is based on the principle of natural selection. The inherent structure of a polymer makes its treatment using GA straightforward-a polymer can be thought of as a sequence of chemical building blocks (e.g. CH2, C6H6, or blocks B12, B13 in Figure 8a) connected to each other by covalent bonds (analogous to DNA base pairs), and the properties of a polymer are functions of the sequence of constituent chemical building blocks (analogous to how oculocutaneous albinism II (OCA2) gene sequence mostly dictates human eye color). Within the GA approach a series of crossover, mutation and selection operations are applied to discover new candidate polymers with desired properties. It starts with a random generation of (say, 100) polymers, whose chemical building blocks are modified using crossover-pruning and mixing of monomer building blocks-and mutation-random alterations to monomer building blocks-operations to obtain a large set of offspring polymers, as illustrated in Figure 8a). Next, the top offspring candidates with desired properties are selected based on their user-defined objective score to form the next generation of polymers. This GA cycle is repeated until a sufficient number of candidates with desired properties are obtained, as in Figure 8b). Besides polymer discovery, GA has also been utilized to solve other problems in materials science, such as developing functional forms of interatomic potentials [133], and discovering hidden material property\\n\\n## Page 17\\n\\nrelations [134].\\nA critical component of the GA design scheme is the evaluation of the objective function during the selection stage. This step has been a major bottleneck for polymer discovery since property estimation through experiments or computations is very expensive and time-consuming [135]. However, with the recent development of cheap and reliable polymer property models (Section 5.1), the objective function can now be computed in a fraction of a second. This allows the GA process to truly explore a very rich chemical polymer space, going well-beyond the pre-defined candidate sets. Furthermore, by setting-up a property weighted objective function, polymers that simultaneously satisfy multiple property criteria can be targeted.\\nKim and co-workers used GA to design polymers with high glass transition temperature and large band gap, which are useful for high-energy capacitors because of their stability at both high temperatures and electric fields [128]. Notably, this is a difficult design problem, with only 4 out of thousands of known polymers displaying glass transition temperature > 500 K and band gap > 6 eV. Two interesting aspects of their design process was the choice of the chemical building blocks, and the underlying property prediction models. The former consisted of a comprehensive list of 3,045 chemical blocks, extracted from ~ 12,000 synthetically known polymers using the concept of BRICS-similar to the hypothetical polymer design work in Section 2. Each block had 1 - 4 connection points that were used to form/break bonds with other chemical blocks during the crossover and mutation operations. For the latter glass transition temperature and band gap prediction models, they used two independent GPR surrogate models based on a hierarchical polymer fingerprinting scheme (Section 3) that were trained on an experimental and DFT computed dataset of 5,072 and 562 polymers, respectively. During 100 generations of the GA cycle, they successfully designed 132 new polymers that meet the target properties, as opposed to only 4 previously known cases (see Figure 8c)). Furthermore, their analysis of the identified polymer candidates revealed insights about the key fragments that promote high glass transition temperature and large band gap in polymers, such as the presence of terminal difluorocarbon or trifluoromethyl, saturated 5-or 6-membered rings, oxolane, etc. These findings are compatible with known chemistry. For instance, fluorine atoms induce large band gap through the formation of lower (higher) C-F sigma bonding (anti-bonding) orbitals. A similar approach has been utilized to design polymers with high dielectric constant, although it considered a relatively small number of possible chemical building blocks [51].\\nIn a different study, Pilania et al. used GA to design bio-advantaged (biosynthesizable and biodegrad- able) Polyhydroxyalkanoate (PHA)-based polymers with desired glass transition temperature values [129]. A machine learning model trained on an experimentally-measured and carefully-curated glass transition temperature values for a wide range of PHA homo- and co-polymers were combined with a GA-based search and optimization routine to explore a much wider chemical space formed by multi-component polymer chemistries, beyond co-polymers. Furthermore, by explicitly integrating the prediction uncertainties and number of polymer components in the GA objective function, they were able to focus their search on poly- mers containing desired number of components (ternary, quaternary, etc.) where the confidence level in the machine-learned glass transition temperature predictions were higher than a pre-specified cutoff value.\\n5.4. Generative models\\nBased on the concept of unsupervised learning, VAE and GAN offer a different route for targeting inverse polymer design. They learn a mapping from a continuous latent space to the polymer space, using which new candidates with desired properties are generated after solving the optimization problem in the more amenable latent space. For example, in the case of VAE, the encoder unit learns to represent a polymer in a high-dimensional (say, 100 - 200) continuous (latent) space, while the decoder unit learns to map back a vector in the latent space to a valid polymer, as shown in Figure 8d). Both mappings are important from a materials design perspective: the encoder provides a fingerprinting scheme that can be exploited by different \"forward models\", while the decoder provides a pathway to systematically search polymers in a proxy latent space using different optimization schemes, and later generate the desired polymer candidate associated with the optimal latent point. Although the VAE and GAN approaches have received attention for molecule or drug discovery [136-140], they are only beginning to be exploited for extended systems such as polymers.\\n\\n## Page 18\\n\\nA key challenge in developing such a generative model is that the decoder unit should map a continuous latent space to a discrete and structured material space, which should represent a valid candidate material as dictated by chemistry. For example, in case of polymers, the decoder output should necessarily have two chain ends, or the involved C and O atoms should display a valency of 4 and 2, respectively. This goal of enforcing the decoder to output valid polymers was recently achieved by Batra et al. [44] using syntax- directed VAE. The strategy involves representing the polymers using their SMILES representation, and then imposing the decoder to obey both the syntactic and semantic constraints associated with the class of polymers; syntactic refers to the grammatical rules inherent to the SMILES language, while semantic refers to the contextual constraints driven by polymer chemistry. The inclusion of explicit syntax and semantics in the VAE model improves the quality of the learned latent space. It also leads to a high occurrence of valid polymer SMILES upon decoding, making the process of discovery efficient.\\nBatra et al. coupled the unsupervised syntax-directed VAE with the supervised GPR method to discover polymers with high glass transition temperature and large band gap [44]. They used the encoder unit to fingerprint the polymers, which were then mapped to the respective glass transition temperature and band gap values using GPR. To train the VAE model they had to overcome a crucial data sparsity challenge: to-date the total number of chemically diverse polymers synthesized is ~ 12,000, while a VAE model usually requires > 100,000 points for its training. They used retro-synthetic ideas to generate a representative hypothetical dataset of ~ 250,000 polymers, constructed from the previously discussed set of 3,045 chemical building blocks. For the discovery of polymers with target properties, they first encode a few known polymers that satisfy the given design criteria to find regions in the latent space where desirable polymers are expected to be present. Linear interpolations within these preferred regions of the latent space are then used to select latent points for which GPR property predictions meet the desired goals. Finally, the decoder is used to obtain the polymer SMILES associated with such selected latent vectors. Several hundreds of new polymers that meet the target property objectives were generated using this process. We anticipate that the concepts of transfer learning, multi-task learning and semi-supervised learning will advance the use of generative models for polymer discovery.\\nThe following comparisons between the GA and the generative techniques for inverse design can be made. First, GA is relatively easy to interpret and entails little efforts to tune the involved parameters (mutation chance, initial population, etc.). In contrast, VAE models being based on NNs are almost impossible to interpret and often entail hefty parameter tuning efforts. Second, the space explored by GA is somewhat constrained by the polymer building blocks, but the SMILES based polymer representation allows VAE to explore a much wider chemical space in a truly unconstrained manner. Lastly, prior knowledge can be easily incorporated in GA, for instance, by biasing the initial population and/or the mutation operation towards favorable building blocks. However, more comparative studies would be needed in the future to establish methods that are appropriate under different scenarios.\\n6. Application examples\\nPolymers are useful in a range of applications. To be a good candidate for any specific application, they must meet multiple desired property requirements, as summarized in Table 2 for selected applications. Below, we comment on a few such applications, with an emphasis on key properties relevant for those applications which may be used to formulate screening criteria (also captured in Table 2).\\n6.1. Polymer dielectrics design for high energy density capacitors\\nPolymer-based dielectric capacitors are widely used in energy storage devices [4, 5, 141-145]. Given the increasing needs of high energy density capacitors, the development of polymer informatics can significantly facilitate the discovery of novel polymer dielectrics [25, 29, 98, 99, 143]. Typically, good polymer dielectrics for high energy density capacitors need to satisfy several property requirements, e.g., high dielectric constant and high breakdown strength (which is positively correlated with band gap and charge injection barriers of metal/polymer interfaces [146]). Further, polymers with high glass transition temperature are desired for high-temperature capacitors to enhance the thermal stability at extreme temperature [144, 145]. Thus,\\n\\n## Page 19\\n\\nTable 2: Desired properties of polymer candidates for various applications\\n\\n![](elements/table/page_19_Table_139697583830400.png)\\n\\n\\n```\\n\\\\begin{tabular}{l l} \\\\hline Applications & Representative desired polymer properties \\\\\\\\ \\\\hline Capacitors & Large band gap and high charge injection barriers \\\\\\\\ (polymer dielectrics) & high glass transition temperature and dielectric constant \\\\\\\\ \\\\hline Li-ion batteries & Large electrochemical stability window, high ionic conductivity, \\\\\\\\ (polymer electrolytes) & high Li-ion transference and mechanical strength \\\\\\\\ \\\\hline Polymer membrane & High permeability and selectivity for gas pairs \\\\\\\\ \\\\hline Electronic devices (conducting polymers) & High electrical conductivity \\\\\\\\ \\\\hline \\\\end{tabular}\\n```\\n\\nthe criteria of high glass transition temperature and €, large band gap and high charge injection barriers can be utilized, in combination with machine learning, to screen polymer candidates tailored to extreme high-temperature and electric field. For instance, several representative dielectrics films with high dielectric constant and band gap, have been successfully designed and synthesized using computation- and data- driven strategies [25, 99]. Additionally, many representative polymer dielectrics are being proposed for high- temperature capacitors by either screening known/hypothetical polymers using the enumeration method [52, 146] or using the generative models, such as GA [128] and VAE [44], as described in Section 5.\\n6.2. Polymer membrane design for gas separation\\nPolymers are also promising candidates for gas separation due to their high surface area [42, 147, 148]. A typical class of polymers called polymers of intrinsic microporosity, has attracted great attention since the early 1990s [147]. The present polymer membranes suffer from low selectivity and physical aging, calling for the exploration of novel polymeric membranes. However, it is non-trivial to find promising polymer membranes with a combination of high permeability and selectivity (or above the upper bound of \"Robeson plots\" [149]) for different gas pairs, e.g., O2/N2. Some initial attempts have been performed to speed up the polymer membrane search using data-driven approaches, for instance, building gas permeability prediction models [111] (see Section 4) and identifying polymer membrane candidates for CO2/CH4 separation using the enumeration method [42].\\n6.3. Polymer electrolytes design for Li-ion batteries\\nRechargeable Li-ion batteries have been widely adopted in many applications from micro-electronics to aerospace. Motivated by their commercial need, the development of novel and safer solid polymer electrolyte materials has caught ever-increasing attention [10, 150-152]. To optimize the performance of Li-ion batteries, the polymer electrolytes should have a wide electrochemical stability window, high ionic conductivity and Li-ion transference, and low glass transition temperature. Since it is time-consuming to search optimal electrolytes using experiments, data-driven aided polymer design strategies provide a great opportunity. For example, we previously noted that Wang et al. designed novel polymer electrolytes with high ionic conductivity using machine learning aided coarse-grained molecular dynamics simulations [37]. Additionally, the property prediction models (Section 4) and the design algorithms (Section 5) discussed above are powerful methods to screen/design polymer electrolytes satisfying multiple property requirements.\\n6.4. Conducting polymers design for electronic applications\\nAlthough polymers are usually insulators, there is a class of intrinsically conducting polymers used in electronic devices, such as light-emitting diodes, field-effect transistors and organic solar cells [6, 153, 154]. Molecular doping is often used to further increase the conductivity of polymers [153], but it slows down the discovery of optimal polymer-dopant pairs with high conductivity because of the complex nature of the electron transfer mechanisms, dopants and polymers interactions, and processing conditions. This situation can be improved using polymer informatics, e.g. developing conductivity prediction models and screening optimal polymer-dopants pairs using the enumeration method. It is supported by the discovery of several high-performing donor/acceptor pairs for organic solar cells using random forest and boosted regression trees based property prediction models [53].\\n\\n## Page 20\\n\\n6.5. Biodegradable and depolymerizable polymers discovery\\nBioplastics, such as those derived from plants and bacteria, are rich in highly oxygenated molecules. They can be utilized in the production of monomers capable of facile conversion to plastic materials that are easily degradable in the environment [155]. However, to fully harness the power of these nonconventional biosynthesis routes, it needs to establish structure-property relationships to identify desired application- specific optimal chemistries. To understand this problem better, Pilania et al. have proposed a machine learning route to learn structure-property mappings in PHA-based polymers from polymer data [129]. More- over, it is critical to discover new biodegradable polymer candidates with high biodegradability. Because low crystallinity, melting temperature and glass transition temperature lead to large amorphous regions and favor biodegradation, ration-design of biodegradable polymers satisfying these properties using data-driven methods can be an important research topic. For instance, some new biodegradable polymers with desired glass transition temperature have been designed recently using GA [129] (see Section 5).\\nAdditionally, depolymerizable polymers are playing an increasingly important role in practical applica- tions, especially in drug delivery, recyclable plastics, self-healing and recyclable coating materials [156, 157]. Such great interest is motivated by the fact that depolymerizable polymers, upon exposure to particular stimuli, can be triggered to rapidly depolymerize into monomers at moderate to relatively low tempera- tures. As a result, polymers with low ceiling temperatures are desirable, where ceiling temperature is the temperature at which the polymerization and depolymerization rates are in equilibrium. Because of the limited available number of known polymers with low ceiling temperatures, it is greatly desired to propose computational strategies to estimate the ceiling temperature. Further, the data-driven design tools involved in polymer informatics could be applied to rapidly screen such depolymerizable polymers.\\n7. Critical next steps\\n7.1. Beyond homopolymers\\nSo far, many data-driven approaches have been limited to homopolymers. The space of co-polymers, polymer blends and polymers with additives/nanocomposites remains largely unexplored but has great prac- tical significance. Brinson and co-workers have spent significant efforts to develop \"NanoMine\" for polymer nanocomposites analysis and design [158]. However, it is still non-trivial to treat these types of polymers, because of their complicated chemical and physical structures. Co-polymers consist of two/more monomer or basic building unit types, and could be branched or linear co-polymers (further classified as block, al- ternating and random co-polymers based on the structural arrangement of different monomers). Polymer blends are mixtures of two or more polymers, including homogeneous, immiscible and heterogeneous polymer blends. The ratios and structural arrangements of different monomers (or polymers) significantly impact properties of co-polymers and polymer blends, but only sparse data is available on this topic. Moreover, it is challenging to systematically and dynamically collect such data from various resources. Thus, advanced techniques need to be developed to collect, represent and learn data of more complex varieties of polymers.\\n7.2. Sustainable data capture\\nThe core requirement for polymer informatics is a broad-based data acquisition and management in- frastructure. In addition to the limited number of available polymer databases and polymer handbooks, a large amount of scientific data remains untapped in numerous scientific journals, including text, tables or figures. While the manual text excerption of such journals is very time consuming and laborious, machine learning-based NLP methods are more powerful and promising tools to expedite and automate this process. The application of NLP tools in material science is still in its infancy. More efforts are needed to incorporate materials or polymers domain knowledge into existing NLP algorithms (e.g., word2vec [159]) to train word- vectors (numerical vectors that represent distinct words) for scientific information retrieval. To achieve this goal, Named Entities Recognition (NER) is the most important step, i.e., tokenizing the words into scientific meanings (e.g., chemical species, synthesis conditions and characterization methods). ChemDataExtractor [160], ChemSpot [161] and ChemTagger [162] are available toolkits for extracting chemical information of\\n\\n## Page 21\\n\\nmaterials from scientific articles, such as inorganics and molecules. Similar tools need to be developed for the polymer domain.\\nHowever, polymers pose additional challenges [21, 26], as there is no standard or complete polymer name entity dictionaries. A collection of source-based, structure-based, traditional and abbreviation names are interchangeably used to name polymers [26]. For example, polyethylene is also called PE, poly(ethylene) and poly-(ethylene), but all these possible names should be treated as the same entity (in a process referred to as \"normalization\" by the NLP community). In addition to names, more efforts are required to assign polymer notations for specific categories, e.g., properties, synthesis recipes and characterization technologies. Therefore, it is of great importance to create unique and standard polymer related dictionaries in the future. Other important issues include building efficient toolkits to interpret monomer SMILES from polymer names, identifying structure (or polymer names)-property relationships in texts, and extracting valuable material property contained in images and tables.\\n7.3. Polymer representation and learning\\nAs discussed in Section 3, molecular or polymer-based fingerprints can provide acceptable prediction ac- curacy for many polymer properties, e.g., glass transition temperature, band gap, dielectric constant and gas permeability. This is because the chemical structure of the monomers plays a dominant role in determining these properties. However, other important polymer properties, including crystallinity, mechanical proper- ties (e.g., tensile strength) and solution behavior, strongly depend on their molecular weights, morphologies (linear or cross-link) and processing conditions (temperature, pressure and cooling-rates). Incorporating these descriptors in the fingerprint framework is critical to the creation of accurate, robust and universal property prediction models.\\nIn addition to enriching the polymer fingerprint definition, more advanced neural networks algorithms can be applied for learning the latent knowledge, property prediction and polymer generations. For instance, the transfer-learning or multi-task learning approaches have great potential to deal with the sparse data issue in polymers. The former modifies the latent features learned using one source task to learn a different target task, while the latter trains multiple source tasks and the shared features used to learn a target task. The key concept common between these two methods is the learning of a shared (polymer) representation between related properties (or materials). These algorithms have been successfully applied in the domain of drug design and bioinformatics [163-165]. In polymers, as mentioned in Section 4, Yamada et al. have used the transfer-learning method to predict properties of polymers using pre-trained models of molecules and inorganic materials [125]. However, large and diverse datasets of related property (tasks) are essential for the success of such models, as only then there is a high chance of learning transferable features and achieving accurate predictions for the target task.\\nAnother important topic is the use of graph neural networks (GNN) in polymer informatics. In contrast to traditional manually designed fragment-based ML models, GNN represents materials as graphs (typically, atoms as nodes and their bonds as edges) and automatically find their optimal fingerprint representation depending on the downstream learning task, leading to its wide applications for molecules. However, the use of GNN for polymers has been limited [104, 124] owing to the difficulty in treating large-scale polymers using graphs. Further, polymers are made up of numerous repeat units, and the best way to treat connection points between repeat units in a graph is unclear. Using oligomers to replace polymers is a potential solution [104, 124], however, its prediction capability needs to be tested. Additionally, ideas on graph generative methods for molecules, e.g., atoms- and substructure-based encoder-decoder methods [45] could be extended for polymers using GNN. Another interesting approach of graph-to-graph translation was recently put forth to optimize molecules with desired properties, by assembling one molecular graph with another of the target properties [46]. All of these techniques can be adapted for polymers, provided the following challenges are addressed. Many polymers have large-sized monomers (> 50 atoms), making it difficult to correctly assemble potential fragments during the decoding process. Motifs-based methods can greatly increase the reconstruction and validation accuracy for polymer generation by using large-size motifs as building blocks [45]. However, other concerns remain, such as chemical or thermodynamic stability of generated polymers and their synthetic feasibility.\\n\\n## Page 22\\n\\n7.4. Polymer retro-synthesis planning\\nEven with the knowledge of which polymer to make for a given application (designed, for instance, using intuition, computation or machine learning), the realization of the polymer can still be very slow because of synthesis challenges. There are various uncertain factors, such as unavailability, toxicity or high cost of the raw materials or demanding technical steps. In the past, the synthesis pathways adopted for a target polymer have been heavily dependent on the domain knowledge and personal preferences of experimenters. Computer-assisted retro-synthesis techniques have been widely developed in the last several decades to identify a series of reaction pathways leading to the synthesis of a target product. In the domain of molecules, either template-based [54, 166] or template-free [105, 167, 168] machine learning approaches have been built for product prediction and have achieved promising results. However, no such method has been developed yet for the case of polymers. Complications in the polymer synthesis processes, e.g., various polymerization mechanisms (such as addition, ring-opening and condensation polymerization), the selection of optimal monomers and solvent pairs, processing conditions (such as cooling rates or annealing temperatures) will need to be considered. Further, unlike molecules, there is no library of reaction templates for polymerization. Nevertheless, experimental polymer synthesis data is plentiful, which can be accumulated manually or using NLP methods, and processed appropriately to develop machine learning models for polymer synthesis and retro-synthesis planning.\\n7.5. Autonomous integration of experimental and computational workflows\\nAs all the different pieces of AI-assisted chemical search, retro-synthesis planning and processing op- timization come together, the idea of autonomous polymer synthesis and design is expected to become a reality. In fact, examples of autonomous robot researchers with the ability to synthesize drugs for tropi- cal diseases [169], carbon nanotubes with targeted growth rates [170], layered superlattices [171], and even perform x-ray scattering measurements [172], have already been demonstrated recently. However, polymers owing to their structural, chemical and processing complexity pose unique challenges for autonomous de- sign. For instance, the average molecular weight of a polymer, which predominantly dictates its properties, is highly sensitive to the processing time and conditions. Learning such complex relations, from the data alone, will be challenging for an autonomous researcher. The real-time/in-line characterization of polymers is also difficult owing to their complex semi-crystalline/amorphous structure, or due to the different degree of branching or stereochemical relationships. Nonetheless, the prowess of autonomous labs in terms of time and cost benefits, experimentation consistency, long hours of operation, and efficient and robust search of parameter spaces is expected to guide polymer discovery in the future.\\n8. Acknowledgments\\nThis work has benefited from the generous support by the Office of Naval Research, the Toyota Re- search Institute, the Department of Energy and the National Science Foundation on machine learning related research through several grants. G. P. acknowledges support from the Laboratory Directed Research and Development (LDRD) program of Los Alamos National Laboratory under the BioManIAC project # 20190001DR. C. Ku. acknowledges support from the Alexander von Humboldt Foundation. R.B acknowl- edges support by LDRD funding from Argonne National Laboratory, provided by the Director, Office of Science, of the U.S. Department of Energy under Contract No. DE-AC02-06CH11357, and the use of the Center for Nanoscale Materials, an Office of Science user facility, supported by the U.S. Department of En- ergy, Office of Science, Office of Basic Energy Sciences, under Contract No. DE-AC02-06CH11357. Joseph Kern is gratefully acknowledged for a critical reading of the manuscript.\\nReferences\\n[1] A. J. Peacock, A. Calhoun, Polymer Chemistry: Properties and Application, Carl Hanser Verlag GmbH Co KG, 2012.\\n[2] P. C. Hiemenz, T. P. Lodge, Polymer chemistry, CRC press, 2007.\\n[3] C. Wong, Polymers for electronic & photonic application, Elsevier, 2013.\\n\\n## Page 23\\n\\n[4] T. D. Huan, B. Steve, T. Gilbert, L. Christian, C. Miko, K. Sanat, R. Rampi, Advanced polymeric dielectrics for high energy density applications, Prog. Mater. Sci. 83 (2016) 236 - 269.\\n[5] Q. Tan, P. Irwin, Y. Cao, Advanced dielectrics for capacitors, IEEJ Trans. FM 126 (11) (2006) 1153-1159.\\n[6] A. C. Mayer, S. R. Scully, B. E. Hardin, M. W. Rowell, M. D. McGehee, Polymer-based solar cells, Mater. Today 10 (11) (2007) 28-33.\\n[7] F. M. Haque, S. M. Grayson, The synthesis, properties and potential applications of cyclic polymers, Nat. Chem. (2020) 1-12.\\n[8] T. Leigh, P. Fernandez-Trillo, Helical polymers for biological and medical applications, Nat. Rev. Chem. (2020) 1-20.\\n[9] K. Ghosal, B. D. Freeman, Gas separation using polymer membranes: an overview, Polym. Adv. Technol. 5 (11) (1994) 673-697.\\n[10] C. Sequeira, D. Santos, Polymer electrolytes: fundamentals and applications, Elsevier, Amsterdam, Netherlands, 2010.\\n[11] R. Geyer, J. R. Jambeck, K. L. Law, Production, use, and fate of all plastics ever made, Sci. Adv. 3 (7) (2017) e1700782.\\n[12] M. I. Jordan, T. M. Mitchell, Machine learning: Trends, perspectives, and prospects, Science 349 (6245) (2015) 255-260.\\n[13] A. Gopnik, Making ai more human., Sci. Am. 316 (6) (2017) 60-65.\\n[14] Y. Liu, T. Zhao, W. Ju, S. Shi, Materials discovery and design using machine learning, J. Materiomics. 3 (3) (2017) 159-177.\\n[15] B. Meredig, Five high-impact research areas in machine learning for materials science, Chem. Mater. 31 (23) (2019) 9579-9581. arXiv: https://doi.org/10.1021/acs. chemmater. 9b04078, doi : 10.1021/acs. chemmater. 9b04078.\\n[16] J. Schmidt, M. R. Marques, S. Botti, M. A. Marques, Recent advances and applications of machine learning in solid-state materials science, NPJ Comput. Mater. 5 (1) (2019) 1-36.\\n[17] T. J. Oweida, A. Mahmood, M. D. Manning, S. Rigin, Y. G. Yingling, Merging materials and data science: Opportunities, challenges, and education in materials informatics, MRS Adv. 5 (7) (2020) 329-346. doi: 10.1557/adv.2020.171.\\n[18] O. Kononova, H. Huo, T. He, Z. Rong, T. Botari, W. Sun, V. Tshitoyan, G. Ceder, Text-mined dataset of inorganic materials synthesis recipes, Sci. Data 6 (1) (2019) 203. doi: 10.1038/s41597-019-0224-1.\\n[19] R. Ramprasad, R. Batra, G. Pilania, A. Mannodi-Kanakkithodi, C. Kim, Machine learning in materials informatics: recent applications and prospects, NPJ Comput. Mater. 3 (1) (2017) 54.\\n[20] D. J. Audus, J. J. de Pablo, Polymer informatics: Opportunities and challenges, ACS Macro Lett. 6 (10) (2017) 1078- 1082, pMID: 29201535. arXiv:https://doi.org/10.1021/acsmacrolett. 7b00228, doi: 10.1021/acsmacrolett. 7b00228. [21] J. S. Peerless, N. J. Milliken, T. J. Oweida, M. D. Manning, Y. G. Yingling, Soft matter informatics: current progress and challenges, Adv. Theory Simul. 2 (1) (2019) 1800129.\\n[22] C. Kim, A. Chandrasekaran, T. D. Huan, D. Das, R. Ramprasad, Polymer genome: A data-powered polymer informatics platform for property predictions, J. Phys. Chem. C 122 (31) (2018) 17575-17585.\\n[23] D. H. Tran, K. Chiho, C. Lihua, C. Anand, B. Rohit, V. Shruti, K. Deepak, P. L. Jordan, G. Rishi, S. Pranav, J. L. Manav, Ramprasad, S. Madeline, R. Rampi, Machine-learning predictions of polymer properties with polymer genome.\\n[24] A. Chandrasekaran, C. Kim, R. Ramprasad, Polymer genome: A polymer informatics platform to accelerate polymer discovery, in: Machine Learning Meets Quantum Physics, Springer, 2020, pp. 397-412.\\n[25] A. Mannodi-Kanakkithodi, A. Chandrasekaran, C. Kim, T. D. Huan, G. Pilania, V. Botu, R. Ramprasad, Scoping the polymer genome: A roadmap for rational polymer dielectrics design and beyond, Mater. Today 21 (7) (2018) 785-796. [26] N. Adams, P. Murray-Rust, Engineering polymer informatics: Towards the computer-aided design of polymers, Macromol. Rapid Commun. 29 (8) (2008) 615-632.\\n[27] J. Mark, Polymer Data Handbook, Oxford University Press, 1999.\\n[28] S. Otsuka, I. Kuwajima, J. Hosoya, Y. Xu, M. Yamazaki, Polyinfo: Polymer database for polymeric materials design, in: 2011 International Conference on Emerging Intelligent Data and Web Technologies, IEEE, 2011, pp. 22-29.\\n[29] T. D. Huan, A. Mannodi-Kanakkithodi, C. Kim, V. Sharma, G. Pilania, R. Ramprasad, A polymer dataset for accelerated property prediction and design, Sci. Data 3 (2016) 160012. doi: 10.1038/sdata.2016.12.\\n[30] L. Chen, R. Batra, R. Ranganathan, G. Sotzing, Y. Cao, R. Ramprasad, Electronic structure of polymer dielectrics: The role of chemical and morphological complexity, Chem. Mater. 30 (21) (2018) 7699-7706. arXiv:https://doi.org/10. 1021/acs. chemmater. 8b02997, doi : 10.1021/acs. chemmater. 8b02997.\\n[31] L. Chen, S. Venkatram, C. Kim, R. Batra, A. Chandrasekaran, R. Ramprasad, Electrochemical stability window of poly- meric electrolytes, Chem. Mater. 31 (12) (2019) 4598-4604. arXiv:https://doi.org/10.1021/acs.chemmater.9b01553, doi: 10.1021/acs. chemmater. 9b01553.\\n[32] H. S. Kim, S. M. Huang, Y. G. Yingling, Sequence dependent interaction of single stranded dna with graphitic flakes: atomistic molecular dynamics simulations, MRS Adv. 1 (25) (2016) 1883-1889. doi: 10.1557/adv.2016.91.\\n[33] K .- H. Shen, L. M. Hall, Ion conductivity and correlations in model salt-doped polymers: Effects of interaction strength and concentration, Macromolecules 53 (10) (2020) 3655-3668. arXiv:https://doi.org/10.1021/acs.macromol. 0c00216, doi: 10.1021/acs.macromol.0c00216.\\n[34] S. Zhu, N. Lempesis, P. J. in ât Veld, G. C. Rutledge, Molecular simulation of thermoplastic polyurethanes under large compressive deformation, Macromolecules 51 (22) (2018) 9306-9316. arXiv:https://doi.org/10.1021/acs.macromol. 8b01922, doi: 10.1021/acs.macromol.8b01922.\\n[35] S. Mogurampelly, O. Borodin, V. Ganesan, Computer simulations of ion transport in polymer electrolyte membranes, Annual review of chemical and biomolecular engineering 7 (2016) 349-371.\\n[36] Y. Seo, K .- H. Shen, J. R. Brown, L. M. Hall, Role of solvation on diffusion of ions in diblock copolymers: Understanding the molecular weight effect through modeling, J. Am. Chem. Soc. 141 (46) (2019) 18455-18466, pMID: 31674178. arXiv: https://doi.org/10.1021/jacs.9b07227, doi: 10.1021/jacs.9b07227.\\n[37] Y. Wang, T. Xie, A. France-Lanord, A. Berkley, J. A. Johnson, Y. Shao-Horn, J. C. Grossman, Toward designing highly\\n\\n## Page 24\\n\\nconductive polymer electrolytes by machine learning assisted coarse-grained molecular dynamics, Chem. Mater. 32 (10) (2020) 4144-4151. arXiv:https://doi.org/10.1021/acs.chemmater.9b04830, doi: 10.1021/acs.chemmater. 9b04830.\\n[38] Y. An, S. Singh, K. K. Bejagam, S. A. Deshmukh, Development of an accurate coarse-grained model of poly(acrylic acid) in explicit solvents, Macromolecules 52 (13) (2019) 4875-4887. arXiv:https://doi.org/10.1021/acs.macromol.9b00615, doi: 10.1021/acs.macromol.9b00615.\\n[39] Y. An, S. A. Deshmukh, Machine learning approach for accurate backmapping of coarse-grained models to all-atom models, Chem. Comm. 56 (65) (2020) 9312-9315.\\n[40] T. D. Huan, R. Ramprasad, Polymer structure prediction from first principles, J. Phys. Chem. Lett. 11 (15) (2020) 5823-5829, pMID: 32609529. doi: 10.1021/acs. jpclett. 0c01553.\\n[41] D. Weininger, Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules, J. Chem. Inf. Comput. Sci. 28 (1) (1988) 31-36. doi: 10.1021/ci00057a005.\\n[42] J. W. Barnett, C. R. Bilchak, Y. Wang, B. C. Benicewicz, L. A. Murdock, T. Bereau, S. K. Kumar, Designing exceptional gas-separation polymer membranes using machine learning, Sci. Adv. 6 (20) (2020) eaaz4301.\\n[43] S. Wu, Y. Kondo, M .- a. Kakimoto, B. Yang, H. Yamada, I. Kuwajima, G. Lambard, K. Hongo, Y. Xu, J. Shiomi, et al., Machine-learning-assisted discovery of polymers with high thermal conductivity using a molecular design algorithm, NPJ Comput. Mater. 5 (1) (2019) 1-11.\\n[44] R. Batra, H. Dai, H. Tran, L. Chen, C. Kim, G. Will, L. Song, R. Ramprasad, Polymers for extreme conditions designed using syntax-directed variational autoencoders, Under Review.\\n[45] W. Jin, R. Barzilay, T. Jaakkola, Hierarchical generation of molecular graphs using structural motifs, arXiv preprint arXiv:2002.03230.\\n[46] W. Jin, K. Yang, R. Barzilay, T. Jaakkola, Learning multimodal graph-to-graph translation for molecular optimization (2018). arXiv: 1812.01070.\\n[47] R. Batra, G. Pilania, B. P. Uberuaga, R. Ramprasad, Multifidelity information fusion with machine learning: A case study of dopant formation energies in hafnia, ACS Appl. Mater. Interfaces 11 (28) (2019) 24906-24918.\\n[48] A. Patra, R. Batra, A. Chandrasekaran, C. Kim, T. D. Huan, R. Ramprasad, A multi-fidelity information-fusion approach to machine learn and predict polymer bandgap, Comput. Mater. Sci. 172 (2019) 109286.\\n[49] A. Chandrasekaran, C. Kim, S. Venkatram, R. Ramprasad, A deep learning solvent-selection paradigm powered by a massive solvent/nonsolvent database for polymers, Macromolecules 53 (12) (2020) 4764-4769. arXiv:https://doi.org/ 10.1021/acs.macromol.0c00251, doi: 10.1021/acs.macromol. 0c00251.\\n[50] A. Mannodi-Kanakkithodi, G. Treich, T. D. Huan, R. Ma, M. Tefferi, Y. Cao, G. Sotzing, R. Ramprasad, Rational co-design of polymer dielectrics for energy storage, Adv. Mater. 28 (2016) 6277-6291.\\n[51] A. Mannodi-Kanakkithodi, G. Pilania, T. D. Huan, T. Lookman, R. Ramprasad, Machine learning strategy for the accelerated design of polymer dielectrics, Sci. Rep. 6 (2016) 20952. doi: 10.1038/srep20952.\\n[52] L. Chen, C. Kim, R. Batra, J. P. Lightstone, C. Wu, Z. Li, A. A. Deshmukh, Y. Wang, H. D. Tran, P. Vashishta,\\net al., Frequency-dependent dielectric constant prediction of polymers using machine learning, NPJ Comput. Mater. 6 (1) (2020) 1-9.\\n[53] Y. Wu, J. Guo, R. Sun, J. Min, Machine learning for accelerating the discovery of high-performance donor/acceptor pairs in non-fullerene organic solar cells, NPJ Comput. Mater. 6 (1) (2020) 1-8.\\n[54] C. W. Coley, R. Barzilay, T. S. Jaakkola, W. H. Green, K. F. Jensen, Prediction of organic reaction outcomes using machine learning, ACS Cent. Sci. 3 (5) (2017) 434-443.\\n[55] C. W. Coley, D. A. Thomas, J. A. Lummiss, J. N. Jaworski, C. P. Breen, V. Schultz, T. Hart, J. S. Fishman, L. Rogers, H. Gao, et al., A robotic platform for flow synthesis of organic compounds informed by ai planning, Science 365 (6453) (2019) eaax1566.\\n[56] J. Brandrup, E. H. Immergut, E. A. Grulke, A. Abe, D. R. Bloch, Polymer handbook, Vol. 7, Wiley New York etc, 1989.\\n[57] G. Wypych, Handbook of polymers, Elsevier, 2016.\\n[58] D. van Krevelen, K. te Nijenhuis, Properties of Polymers: Their Correlation with Chemical Structure; their Numerical Estimation and Prediction from Additive Group Contributions, Elsevier Science, 2009.\\n[59] J. E. Mark, Polymer data handbook, 2009.\\n[60] http://www.polymerdatabase.com, howpublished = http://www.polymerdatabase.com,.\\n[61] B. Ellis, R. Smith, Polymers: a property database, CRC Press, 2008.\\n[62] https://www.campusplastics.com, howpublished = https://www. campusplastics. com,.\\n[63] J. Pionteck, M. Pyda, Polymer solids and polymer melts, part 2, thermodynamic properties-pvt-data and thermal properties-landolt-boernstein-polymer (2014).\\n[64] https://pppdb.uchicago.edu, howpublished = https://pppdb. uchicago. edu,.\\n[65] https://khazana.gatech.edu, howpublished = https://khazana.gatech.edu,.\\n[66] D. Braun, H. Cherdron, M. Rehahn, H. Ritter, B. Voit, Polymer synthesis: theory and practice: fundamentals, methods, experiments, Springer Science & Business Media, 2012.\\n[67] V. Tshitoyan, J. Dagdelen, L. Weston, A. Dunn, Z. Rong, O. Kononova, K. A. Persson, G. Ceder, A. Jain, Unsupervised word embeddings capture latent knowledge from materials science literature, Nature 571 (7763) (2019) 95-98.\\n[68] E. Kim, K. Huang, A. Saunders, A. McCallum, G. Ceder, E. Olivetti, Materials Synthesis Insights from Scientific Literature via Text Extraction and Machine Learning, Chem. Mater. 29 (21) (2017) 9436-9444. doi: 10.1021/acs. chemmater. 7b03500.\\n[69] P. Yi, C. R. Locker, G. C. Rutledge, Molecular dynamics simulation of homogeneous crystal nucleation in polyethylene, Macromolecules 46 (11) (2013) 4723-4733.\\n[70] M. Andreev, G. C. Rutledge, A slip-link model for rheology of entangled polymer melts with crystallization, J. Rheol.\\n\\n## Page 25\\n\\n64 (1) (2020) 213-222.\\n[71] A. E. Marlowe, A. Singh, Y. G. Yingling, The effect of point mutations on structure and mechanical properties of collagen-like fibril: A molecular dynamics study, Mater. Sci. Eng. C 32 (8) (2012) 2583-2588.\\n[72] K. C. Daoulas, M. Müller, J. J. De Pablo, P. F. Nealey, G. D. Smith, Morphology of multi-component polymer systems: single chain in mean field simulation studies, Soft Matter 2 (7) (2006) 573-583.\\n[73] L. Chen, T. D. Huan, R. Ramprasad, Electronic structure of polyethylene: Role of chemical, morphological and interfacial complexity, Sci. Rep. 7 (2017) 6128.\\n[74] K. Chenoweth, S. Cheung, A. C. van Duin, W. A. Goddard, E. M. Kober, Simulations on the thermal decomposition of a poly (dimethylsiloxane) polymer using the reaxff reactive force field, J. Am. Chem. Soc. 127 (19) (2005) 7192-7202.\\n[75] A. Vashisth, C. Ashraf, W. Zhang, C. E. Bakis, A. C. Van Duin, Accelerated reaxff simulations for describing the reactive cross-linking of polymers, J. Phys. Chem. A 122 (32) (2018) 6633-6642.\\n[76] A. Vashisth, C. Ashraf, C. E. Bakis, A. C. van Duin, Effect of chemical structure on thermo-mechanical properties of epoxy polymers: Comparison of accelerated reaxff simulations and experiments, Polymer 158 (2018) 354-363.\\n[77] S. Fukushima, S. Tiwari, H. Kumazoe, R. K. Kalia, A. Nakano, F. Shimojo, P. Vashishta, Effects of chemical defects on anisotropic dielectric response of polyethylene, AIP Adv. 9 (4) (2019) 045022.\\n[78] A. Vasilev, T. Lorenz, C. Breitkopf, Thermal conductivity of polyisoprene and polybutadiene from molecular dynamics simulations and transient measurements, Polymers 12 (5) (2020) 1081.\\n[79] S. Shenogin, A. Bodapati, P. Keblinski, A. J. McGaughey, Predicting the thermal conductivity of inorganic and polymeric glasses: The role of anharmonicity, J. Appl. Phys. 105 (3) (2009) 034906.\\n[80] D. V. Guseva, V. Y. Rudyak, P. V. Komarov, B. A. Bulgakov, A. V. Babkin, A. V. Chertovich, Dynamic and static mechanical properties of crosslinked polymer matrices: multiscale simulations and experiments, Polymers 10 (7) (2018) 792.\\n[81] I .- C. Yeh, J. W. Andzelm, G. C. Rutledge, Mechanical and structural characterization of semicrystalline polyethylene under tensile deformation by molecular dynamics simulations, Macromolecules 48 (12) (2015) 4228-4239.\\n[82] C .- L. Pai, M. C. Boyce, G. C. Rutledge, Mechanical properties of individual electrospun pa 6 (3) t fibers and their variation with fiber diameter, Polymer 52 (10) (2011) 2295-2301.\\n[83] D. Kamal, A. Chandrasekaran, R. Batra, R. Ramprasad, A charge density prediction model for hydrocarbons using deep neural networks, Machine Learning: Science and Technology 1 (2) (2020) 025003. doi: 10.1088/2632-2153/ab5929.\\n[84] E. A. Algaer, F. Müller-Plathe, Molecular dynamics calculations of the thermal conductivity of molecular liquids, poly- mers, and carbon nanotubes, Soft Mater. 10 (1-3) (2012) 42-80.\\n[85] M .- X. Zhu, H .- G. Song, Q .- C. Yu, J .- M. Chen, H .- Y. Zhang, Machine-learning-driven discovery of polymers molecular structures with high thermal conductivity, Int. J. Heat Mass Transf. 162 (2020) 120381. doi: https://doi. org/10. 1016/ j. ijheatmasstransfer. 2020. 120381.\\n[86] J. Degen, C. Wegscheid-Gerlach, A. Zaliani, M. Rarey, On the art of compiling and using \\'drug-like\\' chemical fragment spaces, Chem. Med. Chem 3 (10) (2008) 1503-1507. arXiv: https://chemistry-europe.onlinelibrary.wiley.com/doi/ pdf/10.1002/cmdc.200800178, doi: 10.1002/cmdc. 200800178.\\n[87] Rdkit, open source toolkit for cheminformatics.\\n[88] J. Bicerano, Prediction of polymer properties, CRC Press, 2002.\\n[89] T. Le, V. C. Epa, F. R. Burden, D. A. Winkler, Quantitative structure-property relationship modeling of diverse materials properties, Chem. Rev. 112 (5) (2012) 2889-2919, pMID: 22251444. arXiv:https://doi.org/10.1021/cr200066h, doi: 10.1021/cr200066h.\\n[90] X. Yu, X. Wang, X. Li, J. Gao, H. Wang, Prediction of glass transition temperatures for polystyrenes by a four-descriptors qspr model, Macromol. Theory Simul. 15 (1) (2006) 94-99.\\n[91] H. Hasnaoui, M. Krea, D. Roizard, Neural networks for the prediction of polymer permeability to gases, J. Membr. Sci. 541 (2017) 541 - 549. doi:https://doi.org/10.1016/j.memsci.2017.07.031.\\n[92] T .- S. Lin, C. W. Coley, H. Mochigase, H. K. Beech, W. Wang, Z. Wang, E. Woods, S. L. Craig, J. A. Johnson, J. A. Kalow, K. F. Jensen, B. D. Olsen, Bigsmiles: A structurally-based line notation for describing macromolecules, ACS Cent. Sci. 5 (9) (2019) 1523-1531. arXiv:https://doi.org/10.1021/acscentsci.9b00476, doi:10.1021/acscentsci.9b00476.\\n[93] D. Rogers, M. Hahn, Extended-connectivity fingerprints, J. Chem. Inf. Model. 50 (5) (2010) 742-754.\\n[94] M. H. Segler, T. Kogej, C. Tyrchan, M. P. Waller, Generating focused molecule libraries for drug discovery with recurrent neural networks, ACS Cent. Sci. 4 (1) (2018) 120-131.\\n[95] G. B. Goh, N. O. Hodas, C. Siegel, A. Vishnu, Smiles2vec: An interpretable general-purpose deep neural network for predicting chemical properties, arXiv preprint arXiv:1712.02034.\\n[96] C. Wang, G. Pilania, S. Boggs, S. Kumar, C. Breneman, R. Ramprasad, Computational strategies for polymer dielectrics design, Polymer 55 (4) (2014) 979 - 988.\\n[97] K. Wu, N. Sukumar, N. Lanzillo, C. Wang, R. \"Rampi\" Ramprasad, R. Ma, A. Baldwin, G. Sotzing, C. Breneman, Prediction of polymer properties using infinite chain descriptors (icd) and machine learning: Toward optimized dielectric polymeric materials, J. Polym. Sci. Pol. Phys. 54 (20) (2016) 2082-2091.\\n[98] A. Mannodi-Kanakkithodi, G. Pilania, T. D. Huan, T. Lookman, R. Ramprasad, Machine learning strategy for accelerated design of polymer dielectrics, Sci. Rep. 6.\\n[99] A. Mannodi-Kanakkithodi, G. M. Treich, T. D. Huan, R. Ma, M. Tefferi, Y. Cao, G. A. Sotzing, R. Ramprasad, Rational co-design of polymer dielectrics for energy storage, Adv. Mater. 28 (30) (2016) 6277-6291.\\n[100] D. K. Duvenaud, D. Maclaurin, J. Iparraguirre, R. Bombarell, T. Hirzel, A. Aspuru-Guzik, R. P. Adams, Convolutional networks on graphs for learning molecular fingerprints, in: Advances in neural information processing systems, 2015, pp. 2224-2232.\\n\\n## Page 26\\n\\n[101] S. Kearnes, K. McCloskey, M. Berndl, V. Pande, P. Riley, Molecular graph convolutions: moving beyond fingerprints, J. Comput. Aided Mol. Des. 30 (8) (2016) 595-608.\\n[102] J. Zhou, G. Cui, Z. Zhang, C. Yang, Z. Liu, L. Wang, C. Li, M. Sun, Graph neural networks: A review of methods and applications, arXiv preprint arXiv:1812.08434.\\n[103] X. Yue, Z. Wang, J. Huang, S. Parthasarathy, S. Moosavinasab, Y. Huang, S. M. Lin, W. Zhang, P. Zhang, H. Sun, Graph embedding on biomedical networks: methods, applications and evaluations, Bioinformatics 36 (4) (2019) 1241-1251. arXiv:https://academic.oup.com/bioinformatics/article-pdf/36/4/1241/32527566/btz718.pdf, doi: 10.1093/bioinformatics/btz718.\\n[104] M. Zeng, J. N. Kumar, Z. Zeng, R. Savitha, V. R. Chandrasekhar, K. Hippalgaonkar, Graph convolutional neural networks for polymers property prediction, arXiv preprint arXiv:1811.06231.\\n[105] W. Jin, C. Coley, R. Barzilay, T. Jaakkola, Predicting organic reaction outcomes with weisfeiler-lehman network, in: Advances in Neural Information Processing Systems, 2017, pp. 2607-2616.\\n[106] S. Venkatram, R. Batra, L. Chen, C. Kim, M. Shelton, R. Ramprasad, Predicting crystallization tendency of polymers us- ing multifidelity information fusion and machine learning, J. Phys. Chem. B 124 (28) (2020) 6046-6054, pMID: 32539396. arXiv: https://doi.org/10.1021/acs.jpcb.0c01865, doi : 10. 1021/acs. jpcb. 0c01865.\\n[107] F. Jabeen, M. Chen, B. Rasulev, M. Ossowski, P. Boudjouk, Refractive indices of diverse data set of polymers: A computational qspr based study, Comput. Mater. Sci. 137 (2017) 215-224.\\n[108] V. Venkatraman, B. K. Alsberg, Designing high-refractive index polymers using materials informatics, Polymers 10 (1) (2018) 103.\\n[109] X. Yu, Support vector machine-based qspr for the prediction of glass transition temperatures of polymers, Fibers Polym. 11 (5) (2010) 757-766.\\n[110] G. Pilania, C. Wang, X. Jiang, S. Rajasekaran, R. Ramprasad, Accelerating materials property predictions using machine learning, Sci. Rep. 3 (2013) 2810.\\n[111] G. Zhu, C. Kim, A. Chandrasekarn, J. D. Everett, R. Ramprasad, R. P. Lively, Polymer genome-based prediction of gas permeabilities in polymers, J. Polym. Eng. 1 (ahead-of-print).\\n[112] G. Pilania, P. V. Balachandran, J. E. Gubernatis, T. Lookman, Data-Based Methods for Materials Design and Discovery: Basic Ideas and General Methods, Synthesis Lectures on Materials and Optics 1 (1) (2020) 1-188, publisher: Morgan & Claypool Publishers.\\n[113] P. Zaspel, B. Huang, H. Harbrecht, O. A. von Lilienfeld, Boosting quantum machine learning models with a multilevel combination technique: pople diagrams revisited, J. Chem. Theory Comput. 15 (3) (2018) 1546-1559, publisher: ACS Publications.\\n[114] G. Pilania, J. E. Gubernatis, T. Lookman, Multi-fidelity machine learning models for accurate bandgap predictions of solids, Comput. Mater. Sci. 129 (2017) 156-163, publisher: Elsevier.\\n[115] J. Lee, A. Seko, K. Shitara, K. Nakayama, I. Tanaka, Prediction model of band gap for inorganic compounds by combi- nation of density functional theory calculations and machine learning techniques, Phys. Rev. B 93 (11) (2016) 115104, publisher: APS.\\n[116] R. Ramakrishnan, P. O. Dral, M. Rupp, O. A. von Lilienfeld, Big data meets quantum chemistry approximations: The $\\\\ Delta$-machine learning approach, J. Chem. Theory Comput. 11 (5) (2015) 2087-2096, publisher: ACS Publications.\\n[117] M. C. Kennedy, A. O\\'Hagan, Predicting the output from a complex computer code when fast approximations are available, Biometrika 87 (1) (2000) 1-13, publisher: Oxford University Press.\\n[118] S. Venkatram, C. Kim, A. Chandrasekaran, R. Ramprasad, Critical Assessment of the Hildebrand and Hansen Solubility Parameters for Polymers, J. Chem. Inf. Model. 59 (10) (2019) 4188-4194. doi: 10.1021/acs. jcim. 9b00656.\\n[119] Y. LeCun, Y. Bengio, G. Hinton, Deep learning, Nature 521 (7553) (2015) 436-444.\\n[120] A. Agrawal, A. Choudhary, Deep materials informatics: Applications of deep learning in materials science, MRS Commun. 9 (3) (2019) 779-792.\\n[121] I. Goodfellow, Y. Bengio, A. Courville, Y. Bengio, Deep learning, Vol. 1, MIT press Cambridge, 2016.\\n[122] W. Liu, C. Cao, Artificial neural network prediction of glass transition temperature of polymers, Colloid Polym. Sci. 287 (7) (2009) 811-818.\\n[123] X. Chen, L. Sztandera, H. M. Cartwright, A neural network approach to prediction of glass transition temperature of polymers, Int. J. Intell. Syst. 23 (1) (2008) 22-32.\\n[124] B. G. Sumpter, D. W. Noid, Neural networks and graph theory as computational tools for predicting polymer properties, Macromol. Theory Simul. 3 (2) (1994) 363-378.\\n[125] H. Yamada, C. Liu, S. Wu, Y. Koyama, S. Ju, J. Shiomi, J. Morikawa, R. Yoshida, Predicting materials properties with little data using shotgun transfer learning, ACS Cent. Sci. 5 (10) (2019) 1717-1730. arXiv:https://doi.org/10.1021/ acscentsci.9b00804, doi: 10.1021/acscentsci.9b00804.\\n[126] C. Kim, A. Chandrasekaran, A. Jha, R. Ramprasad, Active-learning and materials design: The example of high glass transition temperature polymers, MRS Commun. 9 (3) (2019) 860-866. doi: 10.1557/mrc.2019.78.\\n[127] T. Lookman, P. V. Balachandran, D. Xue, R. Yuan, Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design, NPJ Comput. Mater. 5 (1) (2019) 1-17.\\n[128] C. Kim, R. Batra, L. Chen, H. Tran, R. Ramprasad, Polymer design using genetic algorithm and machine learning, Comput. Mater. Sci. 186 (2020) 110067.\\n[129] G. Pilania, C. N. Iverson, T. Lookman, B. L. Marrone, Machine-Learning-Based Predictive Modeling of Glass Transition Temperatures: A Case of Polyhydroxyalkanoate Homopolymers and Copolymers, J. Chem. Inf. Model. 59 (12) (2019) 5013-5025, publisher: ACS Publications.\\n[130] T. D. Huan, A. Mannodi-Kanakkithodi, R. Ramprasad, Accelerated materials property predictions and design using\\n\\n## Page 27\\n\\nmotif-based fingerprints, Phys. Rev. B 92 (2015) 014106.\\n[131] D. P. Kingma, M. Welling, Stochastic gradient VB and the variational auto-encoder, in: Second International Conference on Learning Representations, ICLR, Vol. 19, 2014.\\n[132] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio, Generative adversarial nets, in: Advances in neural information processing systems, 2014, pp. 2672-2680.\\n[133] A. Hernandez, A. Balasubramanian, F. Yuan, S. A. Mason, T. Mueller, Fast, accurate, and transferable many-body interatomic potentials by symbolic regression, NPJ Comput. Mater. 5 (1) (2019) 1-11.\\n[134] A. H. Gandomi, S. Sajedi, B. Kiani, Q. Huang, Genetic programming for experimental big data mining: A case study on concrete creep formulation, Autom. Constr. 70 (2016) 89-97.\\n[135] C. D. Fjell, H. Jenssen, W. A. Cheung, R. E. Hancock, A. Cherkasov, Optimization of antibacterial peptides by genetic algorithms and cheminformatics, Chem. Biol. Drug Des. 77 (1) (2011) 48-56.\\n[136] R. Gómez-Bombarelli, J. N. Wei, D. Duvenaud, J. M. Hernández-Lobato, B. Sánchez-Lengeling, D. Sheberla, J. Aguilera- Iparraguirre, T. D. Hirzel, R. P. Adams, A. Aspuru-Guzik, Automatic chemical design using a data-driven continuous representation of molecules, ACS Cent. Sci. 4 (2) (2018) 268-276, pMID: 29532027. arXiv:https://doi.org/10.1021/ acscentsci. 7b00572, doi : 10.1021/acscentsci. 7b00572.\\n[137] M. J. Kusner, B. Paige, J. M. Hernandez-Lobato, Grammar variational autoencoder, in: D. Precup, Y. W. Teh (Eds.), Proceedings of the 34th International Conference on Machine Learning, Vol. 70 of Proceedings of Machine Learning Research, PMLR, International Convention Centre, Sydney, Australia, 2017, pp. 1945-1954.\\n[138] H. Dai, Y. Tian, B. Dai, S. Skiena, L. Song, Syntax-directed variational autoencoder for structured data, arXiv:1802.08786.\\n[139] J. You, B. Liu, R. Ying, V. Pande, J. Leskovec, Graph convolutional policy network for goal-directed molecular graph generation, in: Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS\\'18, Curran Associates Inc., Red Hook, NY, USA, 2018, pp. 6412-6422.\\n[140] N. De Cao, T. Kipf, Molgan: An implicit generative model for small molecular graphs, arxiv.org/abs/1805.11973.\\n[141] B. Chu, X. Zhou, K. Ren, B. Neese, M. Lin, Q. Wang, F. Bauer, Q. M. Zhang, A dielectric polymer with high electric energy density and fast discharge speed, Science 313 (5785) (2006) 334-336.\\n[142] Q. Li, L. Chen, M. R. Gadinski, S. Zhang, G. Zhang, H. U. Li, E. Iagodkine, A. Haque, L .- Q. Chen, T. N. Jackson, et al., Flexible high-temperature dielectric materials from polymer nanocomposites, Nature 523 (7562) (2015) 576.\\n[143] V. Sharma, C. Wang, R. G. Lorenzini, R. Ma, Q. Zhu, D. W. Sinkovits, G. Pilania, A. R. Oganov, S. Kumar, G. A. Sotzing, Rational design of all organic polymer dielectrics, Nat. Commun. 5 (2014) 4845.\\n[144] J. S. Ho, S. G. Greenbaum, Polymer capacitor dielectrics for high temperature applications, ACS Appl. Mater. Interfaces 10 (35) (2018) 29189-29218.\\n[145] C. Wu, A. Deshmukh, Z. Li, , L. Chen, A. Alamri, Y. Wang, R. Ramprasad, G. A. Sotzing, Y. Cao, Flexible temperature- invariant polymer dielectrics with large bandgap, Adv. Mater. (2020) Accepted.\\n[146] D. Kamal, Y. Wang, H. D. Tran, L. Chen, Z. Li, C. Wu, S. Nasreen, Y. Cao, R. Ramprasad, Computable bulk and interfacial electronic structure features as proxies for dielectric breakdown of polymers, ACS Appl. Mater. Interfaces 12 (33) (2020) 37182-37187, pMID: 32705867. arXiv:https://doi.org/10.1021/acsami.0c09555, doi:10.1021/acsami. 0c09555.\\n[147] Z .- X. Low, P. M. Budd, N. B. Mckeown, D. A. Patterson, Gas permeation properties, physical aging, and its mitigation in high free volume glassy polymers, Chem. Rev. 118 (12) (2018) 5871-5911.\\n[148] M. L. Jue, R. P. Lively, Targeted gas separations through polymer membrane functionalization, React. Funct. Polym. 86 (2015) 88-110.\\n[149] L. M. Robeson, The upper bound revisited, J. Membr. Sci. 320 (1-2) (2008) 390-400.\\n[150] R. Agrawal, G. Pandey, Solid polymer electrolytes: materials designing and all-solid-state battery applications: an overview, J. Phys. D: Appl. Phys. 41 (22) (2008) 223001.\\n[151] J. Mindemark, B. Sun, E. Törmä, D. Brandell, High-performance solid polymer electrolytes for lithium batteries opera- tional at ambient temperature, J. Power Sources 298 (2015) 166-170.\\n[152] A. M. Stephan, K. Nahm, Review on composite polymer electrolytes for lithium batteries, Polymer 47 (16) (2006) 5952 - 5964. doi:https://doi.org/10.1016/j.polymer.2006.05.069.\\n[153] A. I. Hofmann, R. Kroon, L. Yu, C. Müller, Highly stable doping of a polar polythiophene through co-processing with sulfonic acids and bistriflimide, J. Mater. Chem. C 6 (26) (2018) 6905-6910.\\n[154] J. Brebels, J. V. Manca, L. Lutsen, D. Vanderzande, W. Maes, High dielectric constant conjugated materials for organic photovoltaics, J. Mater. Chem. A 5 (46) (2017) 24037-24050.\\n[155] A .- C. Albertsson, M. Hakkarainen, Designed to degrade, Science 358 (6365) (2017) 872-873, publisher: American Asso- ciation for the Advancement of Science.\\n[156] J. A. Kaitz, O. P. Lee, J. S. Moore, Depolymerizable polymers: preparation, applications, and future outlook, MRS Commun. 5 (2) (2015) 191-204.\\n[157] A. M. DiLauro, J. S. Robbins, S. T. Phillips, Reproducible and scalable synthesis of end-cap-functionalized depolymer- izable poly (phthalaldehydes), Macromolecules 46 (8) (2013) 2963-2968.\\n[158] H. Zhao, X. Li, Y. Zhang, L. S. Schadler, W. Chen, L. C. Brinson, Perspective: Nanomine: A material genome approach for polymer nanocomposites analysis and design, APL Mater. 4 (5) (2016) 053204.\\n[159] T. Mikolov, K. Chen, G. Corrado, J. Dean, Efficient estimation of word representations in vector space, arXiv preprint arXiv:1301.3781.\\n[160] M. C. Swain, J. M. Cole, Chemdataextractor: a toolkit for automated extraction of chemical information from the scientific literature, J. Chem. Inf. Model. 56 (10) (2016) 1894-1904.\\n\\n## Page 28\\n\\n[161] T. Rocktäschel, M. Weidlich, U. Leser, Chemspot: a hybrid system for chemical named entity recognition, Bioinformatics 28 (12) (2012) 1633-1640.\\n[162] L. Hawizy, D. M. Jessop, N. Adams, P. Murray-Rust, Chemicaltagger: A tool for semantic text-mining in chemistry, J. Cheminformatics 3 (1) (2011) 17.\\n[163] B. Ramsundar, S. Kearnes, P. Riley, D. Webster, D. Konerding, V. Pande, Massively Multitask Networks for Drug Discovery (Icml).\\n[164] B. Ramsundar, B. Liu, Z. Wu, A. Verras, M. Tudor, R. P. Sheridan, V. Pande, Is Multitask Deep Learning Practical for Pharma?, J. Chem. Inf. Model. 57 (8) (2017) 2068-2076. doi: 10.1021/acs. jcim. 7b00146.\\n[165] J. Ma, R. P. Sheridan, A. Liaw, G. E. Dahl, V. Svetnik, Deep neural nets as a method for quantitative structure-activity relationships, J. Chem. Inf. Model. 55 (2) (2015) 263-274. doi: 10.1021/ci500747n.\\n[166] M. H. Segler, M. Preuss, M. P. Waller, Planning chemical syntheses with deep neural networks and symbolic ai, Nature 555 (7698) (2018) 604-610.\\n[167] C. W. Coley, W. Jin, L. Rogers, T. F. Jamison, T. S. Jaakkola, W. H. Green, R. Barzilay, K. F. Jensen, A graph- convolutional neural network model for the prediction of chemical reactivity, Chem. Sci. 10 (2019) 370-377. doi: 10.1039/C8SC04228D.\\n[168] H. Dai, C. Li, C. Coley, B. Dai, L. Song, Retrosynthesis prediction with conditional graph logic network, in: H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlche-Buc, E. Fox, R. Garnett (Eds.), Advances in Neural Information Processing Systems 32, Curran Associates, Inc., 2019, pp. 8872-8882.\\n[169] K. Williams, E. Bilsland, A. Sparkes, W. Aubrey, M. Young, L. N. Soldatova, K. De Grave, J. Ramon, M. De Clare, W. Sirawaraporn, et al., Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases, J. R. Soc. Interface 12 (104) (2015) 20141289.\\n[170] P. Nikolaev, D. Hooper, F. Webber, R. Rao, K. Decker, M. Krein, J. Poleski, R. Barto, B. Maruyama, Autonomy in materials research: A case study in carbon nanotube growth, NPJ Comput. Mater. 2 (1) (2016) 1-6.\\n[171] S. Masubuchi, M. Morimoto, S. Morikawa, M. Onodera, Y. Asakawa, K. Watanabe, T. Taniguchi, T. Machida, Au- tonomous robotic searching and assembly of two-dimensional crystals to build van der waals superlattices, Nat. Commun. 9 (1) (2018) 1-12.\\n[172] M. M. Noack, K. G. Yager, M. Fukuto, G. S. Doerk, R. Li, J. A. Sethian, A kriging-based approach to autonomous experimentation with applications to x-ray scattering, Sci. Rep. 9 (1) (2019) 1-19.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.34 10.29  7.37 10.42]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52.393125999999995, 120.19337399999999, 60.904942999999996, 121.711852)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bbox = [float(i) for i in elements_df.loc[6, \"bounding_box\"][1:-1].split(\",\")]\n",
    "bbox = np.array(bbox)\n",
    "print(bbox)\n",
    "\n",
    "azure_width = 8.2639\n",
    "azure_height = 11.6806\n",
    "\n",
    "# Convert Azure's relative coordinates to PDF points\n",
    "x1 = (bbox[0] * azure_width)\n",
    "y1 = (bbox[1] * azure_height)\n",
    "x2 = (bbox[2] * azure_width)\n",
    "y2 = (bbox[3] * azure_height)\n",
    "\n",
    "x1, y1, x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45.648, 74.088, 53.064, 75.024]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[float(i)/10 for i in elements_df.loc[6, \"normalized_box\"][1:-1].split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nougat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
