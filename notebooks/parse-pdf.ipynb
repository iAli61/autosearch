{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/azureuser/.cache/torch/hub/nougat-0.1.0-small')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nougat.utils.checkpoint import get_checkpoint\n",
    "get_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nougat/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading nougat checkpoint version 0.1.0-small to path nougat_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 557/557 [00:00<00:00, 1.67Mb/s]\n",
      "pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 956M/956M [00:08<00:00, 121Mb/s]\n",
      "special_tokens_map.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 96.0/96.0 [00:00<00:00, 616kb/s]\n",
      "tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.04M/2.04M [00:00<00:00, 15.4Mb/s]\n",
      "tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 106/106 [00:00<00:00, 615kb/s]\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/nougat/model.py:437: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  return torch.var(self.values, 1) / self.values.shape[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selection of suitable polymer-solvent pairs is a critical step for polymer synthesis. Chandrasekaran _et al._ have developed a deep neural network model for solvent prediction [49]. In this work, 4,595 polymers and 24 solvents, forming a total of 11,958 polymer + good-solvent pairs and 8,469 polymer + non-solvent pairs, were used to train a binary classification NN model (i.e., given a polymer-solvent pair the model predicts if it a good-solvent or non-solvent for that polymer). A multilayer perceptron with special architecture was used: the first part of the NN composed of two input branches, one for the polymer descriptors generated using hierarchical fragment-based fingerprint described in Section 3 and the other for the solvent descriptors represented by one-hot encoding. In the second part, polymer and solvent latent space were concatenated into a single merged latent vector. Figure 5 c) shows the neural network prediction accuracy of soluble (top) and insoluble (bottom) polymers for 24 solvents, including non-polar, polar-a-protein and polar-protic solvents. Performance results for the GPR models trained using Hildebrand parameters of about 100 polymers [118] are also compared. In general, the performance of the NN model greatly outperforms that of the GPR model, mainly due to the higher level of diversity in the training data. Further, the Hildebrand parameter is only an approximate empirical approach to distinguish good-solvent against non-solvents, based on the notion of \"like dissolves like\". This deep neural network-based framework provides a more general, accurate, and efficient way to predict good-solvents vs. non-solvents for new polymers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from document_analysis import NougatService\n",
    "\n",
    "# Make sure NOUGAT_CHECKPOINT environment variable is set\n",
    "os.environ[\"NOUGAT_CHECKPOINT\"] = \"nougat_checkpoint\"\n",
    "# Or use the default checkpoint\n",
    "# from nougat.utils.checkpoint import get_checkpoint\n",
    "# os.environ[\"NOUGAT_CHECKPOINT\"] = get_checkpoint()\n",
    "\n",
    "# Initialize service\n",
    "nougat_service = NougatService()\n",
    "\n",
    "# Process image\n",
    "image_path = 'output/0.55/1-s2/elements/page_12_Text_3.png'\n",
    "text = nougat_service.get_text_from_nougat(image_path)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing layout detection model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nougat/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DeformableDetrForObjectDetection were not initialized from the model checkpoint at Aryn/deformable-detr-DocLayNet and are newly initialized: ['bbox_embed.0.layers.0.bias', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'bbox_embed.0.layers.1.weight', 'class_embed.0.bias', 'bbox_embed.0.layers.2.weight', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'bbox_embed.0.layers.1.bias', 'bbox_embed.0.layers.0.weight', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'bbox_embed.0.layers.2.bias', 'class_embed.0.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/anaconda/envs/nougat/lib/python3.9/site-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout detection service initialized. Using device: cuda\n",
      "Processing document: ../tests/files/1-s2.0-S0927796X2030053X-am.pdf\n",
      "Converted 28 pages to images\n",
      "Processing page 1/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_1_layout.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nougat/lib/python3.9/site-packages/nougat/model.py:437: UserWarning: var(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  return torch.var(self.values, 1) / self.values.shape[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 2/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_2_layout.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found repetitions in sample 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 3/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_3_layout.png\n",
      "Processing page 4/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_4_layout.png\n",
      "Processing page 5/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_5_layout.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found repetitions in sample 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 6/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_6_layout.png\n",
      "Processing page 7/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_7_layout.png\n",
      "Processing page 8/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_8_layout.png\n",
      "Processing page 9/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_9_layout.png\n",
      "Processing page 10/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_10_layout.png\n",
      "Processing page 11/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_11_layout.png\n",
      "Processing page 12/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_12_layout.png\n",
      "Processing page 13/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_13_layout.png\n",
      "Processing page 14/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_14_layout.png\n",
      "Processing page 15/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_15_layout.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found repetitions in sample 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 16/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_16_layout.png\n",
      "Processing page 17/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_17_layout.png\n",
      "Processing page 18/28\n",
      "Saved page visualization to: output/0.55/1-s2/visualizations/page_18_layout.png\n"
     ]
    }
   ],
   "source": [
    "# Add these lines at the beginning of your notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from document_analysis import DocumentAnalyzer\n",
    "from glob import glob\n",
    "\n",
    "# Update imports to suppress TqdmWarning or ensure dependencies are updated\n",
    "# Consider adding installation commands if running in a notebook environment\n",
    "# Example:\n",
    "# !pip install --upgrade jupyter ipywidgets\n",
    "\n",
    "# Alternatively, suppress the warning\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tqdm.auto\")\n",
    "\n",
    "# Initialize the analyzer\n",
    "confidence_thresholds = [0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "pdfs_path = \"../tests/files\"\n",
    "pdf_paths = glob(f\"{pdfs_path}/*.pdf\")\n",
    "\n",
    "# Process a document\n",
    "for pdf_path in pdf_paths[0:1]:\n",
    "    for ct in confidence_thresholds[0:1]:\n",
    "        analyzer = DocumentAnalyzer(output_dir=f\"output/{ct}/{pdf_path.split('/')[-1].split('.')[0]}\",\n",
    "                                     confidence_threshold=ct)\n",
    "\n",
    "        # Process a document\n",
    "        result = analyzer.analyze_document(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nougat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
